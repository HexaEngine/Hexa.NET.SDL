// ------------------------------------------------------------------------------
// <auto-generated>
//     This code was generated by a tool.
//
//     Changes to this file may cause incorrect behavior and will be lost if
//     the code is regenerated.
// </auto-generated>
// ------------------------------------------------------------------------------

using System;
using System.Runtime.CompilerServices;
using System.Runtime.InteropServices;
using HexaGen.Runtime;

namespace Hexa.NET.SDL3
{
	public unsafe partial class SDL
	{

		/// <summary>
		/// Determine if an audio device is a playback device (instead of recording).<br/>
		/// This function may return either true or false for invalid device IDs.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// </summary>
		public static bool IsAudioDevicePlayback(uint devid)
		{
			byte ret = IsAudioDevicePlaybackNative(devid);
			return ret != 0;
		}

		/// <summary>
		/// Use this function to pause audio playback on a specified device.<br/>
		/// This function pauses audio processing for a given device. Any bound audio<br/>
		/// streams will not progress, and no audio will be generated. Pausing one<br/>
		/// device does not prevent other unpaused devices from running.<br/>
		/// Unlike in SDL2, audio devices start in an _unpaused_ state, since an app<br/>
		/// has to bind a stream before any audio will flow. Pausing a paused device is<br/>
		/// a legal no-op.<br/>
		/// Pausing a device can be useful to halt all audio without unbinding all the<br/>
		/// audio streams. This might be useful while a game is paused, or a level is<br/>
		/// loading, etc.<br/>
		/// Physical devices can not be paused or unpaused, only logical devices<br/>
		/// created through SDL_OpenAudioDevice() can be.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte PauseAudioDeviceNative(uint devid)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, byte>)funcTable[321])(devid);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<uint, byte>)funcTable[321])(devid);
			#endif
		}

		/// <summary>
		/// Use this function to pause audio playback on a specified device.<br/>
		/// This function pauses audio processing for a given device. Any bound audio<br/>
		/// streams will not progress, and no audio will be generated. Pausing one<br/>
		/// device does not prevent other unpaused devices from running.<br/>
		/// Unlike in SDL2, audio devices start in an _unpaused_ state, since an app<br/>
		/// has to bind a stream before any audio will flow. Pausing a paused device is<br/>
		/// a legal no-op.<br/>
		/// Pausing a device can be useful to halt all audio without unbinding all the<br/>
		/// audio streams. This might be useful while a game is paused, or a level is<br/>
		/// loading, etc.<br/>
		/// Physical devices can not be paused or unpaused, only logical devices<br/>
		/// created through SDL_OpenAudioDevice() can be.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool PauseAudioDevice(uint devid)
		{
			byte ret = PauseAudioDeviceNative(devid);
			return ret != 0;
		}

		/// <summary>
		/// Use this function to unpause audio playback on a specified device.<br/>
		/// This function unpauses audio processing for a given device that has<br/>
		/// previously been paused with SDL_PauseAudioDevice(). Once unpaused, any<br/>
		/// bound audio streams will begin to progress again, and audio can be<br/>
		/// generated.<br/>
		/// Unlike in SDL2, audio devices start in an _unpaused_ state, since an app<br/>
		/// has to bind a stream before any audio will flow. Unpausing an unpaused<br/>
		/// device is a legal no-op.<br/>
		/// Physical devices can not be paused or unpaused, only logical devices<br/>
		/// created through SDL_OpenAudioDevice() can be.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ResumeAudioDeviceNative(uint devid)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, byte>)funcTable[322])(devid);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<uint, byte>)funcTable[322])(devid);
			#endif
		}

		/// <summary>
		/// Use this function to unpause audio playback on a specified device.<br/>
		/// This function unpauses audio processing for a given device that has<br/>
		/// previously been paused with SDL_PauseAudioDevice(). Once unpaused, any<br/>
		/// bound audio streams will begin to progress again, and audio can be<br/>
		/// generated.<br/>
		/// Unlike in SDL2, audio devices start in an _unpaused_ state, since an app<br/>
		/// has to bind a stream before any audio will flow. Unpausing an unpaused<br/>
		/// device is a legal no-op.<br/>
		/// Physical devices can not be paused or unpaused, only logical devices<br/>
		/// created through SDL_OpenAudioDevice() can be.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool ResumeAudioDevice(uint devid)
		{
			byte ret = ResumeAudioDeviceNative(devid);
			return ret != 0;
		}

		/// <summary>
		/// Use this function to query if an audio device is paused.<br/>
		/// Unlike in SDL2, audio devices start in an _unpaused_ state, since an app<br/>
		/// has to bind a stream before any audio will flow.<br/>
		/// Physical devices can not be paused or unpaused, only logical devices<br/>
		/// created through SDL_OpenAudioDevice() can be. Physical and invalid device<br/>
		/// IDs will report themselves as unpaused here.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte AudioDevicePausedNative(uint devid)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, byte>)funcTable[323])(devid);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<uint, byte>)funcTable[323])(devid);
			#endif
		}

		/// <summary>
		/// Use this function to query if an audio device is paused.<br/>
		/// Unlike in SDL2, audio devices start in an _unpaused_ state, since an app<br/>
		/// has to bind a stream before any audio will flow.<br/>
		/// Physical devices can not be paused or unpaused, only logical devices<br/>
		/// created through SDL_OpenAudioDevice() can be. Physical and invalid device<br/>
		/// IDs will report themselves as unpaused here.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool AudioDevicePaused(uint devid)
		{
			byte ret = AudioDevicePausedNative(devid);
			return ret != 0;
		}

		/// <summary>
		/// Get the gain of an audio device.<br/>
		/// The gain of a device is its volume; a larger gain means a louder output,<br/>
		/// with a gain of zero being silence.<br/>
		/// Audio devices default to a gain of 1.0f (no change in output).<br/>
		/// Physical devices may not have their gain changed, only logical devices, and<br/>
		/// this function will always return -1.0f when used on physical devices.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static float GetAudioDeviceGainNative(uint devid)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, float>)funcTable[324])(devid);
			#else
			return (float)((delegate* unmanaged[Cdecl]<uint, float>)funcTable[324])(devid);
			#endif
		}

		/// <summary>
		/// Get the gain of an audio device.<br/>
		/// The gain of a device is its volume; a larger gain means a louder output,<br/>
		/// with a gain of zero being silence.<br/>
		/// Audio devices default to a gain of 1.0f (no change in output).<br/>
		/// Physical devices may not have their gain changed, only logical devices, and<br/>
		/// this function will always return -1.0f when used on physical devices.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static float GetAudioDeviceGain(uint devid)
		{
			float ret = GetAudioDeviceGainNative(devid);
			return ret;
		}

		/// <summary>
		/// Change the gain of an audio device.<br/>
		/// The gain of a device is its volume; a larger gain means a louder output,<br/>
		/// with a gain of zero being silence.<br/>
		/// Audio devices default to a gain of 1.0f (no change in output).<br/>
		/// Physical devices may not have their gain changed, only logical devices, and<br/>
		/// this function will always return false when used on physical devices. While<br/>
		/// it might seem attractive to adjust several logical devices at once in this<br/>
		/// way, it would allow an app or library to interfere with another portion of<br/>
		/// the program's otherwise-isolated devices.<br/>
		/// This is applied, along with any per-audiostream gain, during playback to<br/>
		/// the hardware, and can be continuously changed to create various effects. On<br/>
		/// recording devices, this will adjust the gain before passing the data into<br/>
		/// an audiostream; that recording audiostream can then adjust its gain further<br/>
		/// when outputting the data elsewhere, if it likes, but that second gain is<br/>
		/// not applied until the data leaves the audiostream again.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte SetAudioDeviceGainNative(uint devid, float gain)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, float, byte>)funcTable[325])(devid, gain);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<uint, float, byte>)funcTable[325])(devid, gain);
			#endif
		}

		/// <summary>
		/// Change the gain of an audio device.<br/>
		/// The gain of a device is its volume; a larger gain means a louder output,<br/>
		/// with a gain of zero being silence.<br/>
		/// Audio devices default to a gain of 1.0f (no change in output).<br/>
		/// Physical devices may not have their gain changed, only logical devices, and<br/>
		/// this function will always return false when used on physical devices. While<br/>
		/// it might seem attractive to adjust several logical devices at once in this<br/>
		/// way, it would allow an app or library to interfere with another portion of<br/>
		/// the program's otherwise-isolated devices.<br/>
		/// This is applied, along with any per-audiostream gain, during playback to<br/>
		/// the hardware, and can be continuously changed to create various effects. On<br/>
		/// recording devices, this will adjust the gain before passing the data into<br/>
		/// an audiostream; that recording audiostream can then adjust its gain further<br/>
		/// when outputting the data elsewhere, if it likes, but that second gain is<br/>
		/// not applied until the data leaves the audiostream again.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioDeviceGain(uint devid, float gain)
		{
			byte ret = SetAudioDeviceGainNative(devid, gain);
			return ret != 0;
		}

		/// <summary>
		/// Close a previously-opened audio device.<br/>
		/// The application should close open audio devices once they are no longer<br/>
		/// needed.<br/>
		/// This function may block briefly while pending audio data is played by the<br/>
		/// hardware, so that applications don't drop the last buffer of data they<br/>
		/// supplied if terminating immediately afterwards.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void CloseAudioDeviceNative(uint devid)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<uint, void>)funcTable[326])(devid);
			#else
			((delegate* unmanaged[Cdecl]<uint, void>)funcTable[326])(devid);
			#endif
		}

		/// <summary>
		/// Close a previously-opened audio device.<br/>
		/// The application should close open audio devices once they are no longer<br/>
		/// needed.<br/>
		/// This function may block briefly while pending audio data is played by the<br/>
		/// hardware, so that applications don't drop the last buffer of data they<br/>
		/// supplied if terminating immediately afterwards.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static void CloseAudioDevice(uint devid)
		{
			CloseAudioDeviceNative(devid);
		}

		/// <summary>
		/// Bind a list of audio streams to an audio device.<br/>
		/// Audio data will flow through any bound streams. For a playback device, data<br/>
		/// for all bound streams will be mixed together and fed to the device. For a<br/>
		/// recording device, a copy of recorded data will be provided to each bound<br/>
		/// stream.<br/>
		/// Audio streams can only be bound to an open device. This operation is<br/>
		/// atomic--all streams bound in the same call will start processing at the<br/>
		/// same time, so they can stay in sync. Also: either all streams will be bound<br/>
		/// or none of them will be.<br/>
		/// It is an error to bind an already-bound stream; it must be explicitly<br/>
		/// unbound first.<br/>
		/// Binding a stream to a device will set its output format for playback<br/>
		/// devices, and its input format for recording devices, so they match the<br/>
		/// device's settings. The caller is welcome to change the other end of the<br/>
		/// stream's format at any time with SDL_SetAudioStreamFormat().<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte BindAudioStreamsNative(uint devid, SDLAudioStream** streams, int numStreams)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, SDLAudioStream**, int, byte>)funcTable[327])(devid, streams, numStreams);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<uint, nint, int, byte>)funcTable[327])(devid, (nint)streams, numStreams);
			#endif
		}

		/// <summary>
		/// Bind a list of audio streams to an audio device.<br/>
		/// Audio data will flow through any bound streams. For a playback device, data<br/>
		/// for all bound streams will be mixed together and fed to the device. For a<br/>
		/// recording device, a copy of recorded data will be provided to each bound<br/>
		/// stream.<br/>
		/// Audio streams can only be bound to an open device. This operation is<br/>
		/// atomic--all streams bound in the same call will start processing at the<br/>
		/// same time, so they can stay in sync. Also: either all streams will be bound<br/>
		/// or none of them will be.<br/>
		/// It is an error to bind an already-bound stream; it must be explicitly<br/>
		/// unbound first.<br/>
		/// Binding a stream to a device will set its output format for playback<br/>
		/// devices, and its input format for recording devices, so they match the<br/>
		/// device's settings. The caller is welcome to change the other end of the<br/>
		/// stream's format at any time with SDL_SetAudioStreamFormat().<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool BindAudioStreams(uint devid, SDLAudioStream** streams, int numStreams)
		{
			byte ret = BindAudioStreamsNative(devid, streams, numStreams);
			return ret != 0;
		}

		/// <summary>
		/// Bind a list of audio streams to an audio device.<br/>
		/// Audio data will flow through any bound streams. For a playback device, data<br/>
		/// for all bound streams will be mixed together and fed to the device. For a<br/>
		/// recording device, a copy of recorded data will be provided to each bound<br/>
		/// stream.<br/>
		/// Audio streams can only be bound to an open device. This operation is<br/>
		/// atomic--all streams bound in the same call will start processing at the<br/>
		/// same time, so they can stay in sync. Also: either all streams will be bound<br/>
		/// or none of them will be.<br/>
		/// It is an error to bind an already-bound stream; it must be explicitly<br/>
		/// unbound first.<br/>
		/// Binding a stream to a device will set its output format for playback<br/>
		/// devices, and its input format for recording devices, so they match the<br/>
		/// device's settings. The caller is welcome to change the other end of the<br/>
		/// stream's format at any time with SDL_SetAudioStreamFormat().<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool BindAudioStreams(uint devid, ref SDLAudioStream* streams, int numStreams)
		{
			fixed (SDLAudioStream** pstreams = &streams)
			{
				byte ret = BindAudioStreamsNative(devid, (SDLAudioStream**)pstreams, numStreams);
				return ret != 0;
			}
		}

		/// <summary>
		/// Bind a single audio stream to an audio device.<br/>
		/// This is a convenience function, equivalent to calling<br/>
		/// `SDL_BindAudioStreams(devid, <br/>
		/// &stream<br/>
		/// , 1)`.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte BindAudioStreamNative(uint devid, SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, SDLAudioStream*, byte>)funcTable[328])(devid, stream);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<uint, nint, byte>)funcTable[328])(devid, (nint)stream);
			#endif
		}

		/// <summary>
		/// Bind a single audio stream to an audio device.<br/>
		/// This is a convenience function, equivalent to calling<br/>
		/// `SDL_BindAudioStreams(devid, <br/>
		/// &stream<br/>
		/// , 1)`.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool BindAudioStream(uint devid, SDLAudioStream* stream)
		{
			byte ret = BindAudioStreamNative(devid, stream);
			return ret != 0;
		}

		/// <summary>
		/// Bind a single audio stream to an audio device.<br/>
		/// This is a convenience function, equivalent to calling<br/>
		/// `SDL_BindAudioStreams(devid, <br/>
		/// &stream<br/>
		/// , 1)`.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool BindAudioStream(uint devid, ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = BindAudioStreamNative(devid, (SDLAudioStream*)pstream);
				return ret != 0;
			}
		}

		/// <summary>
		/// Unbind a list of audio streams from their audio devices.<br/>
		/// The streams being unbound do not all have to be on the same device. All<br/>
		/// streams on the same device will be unbound atomically (data will stop<br/>
		/// flowing through all unbound streams on the same device at the same time).<br/>
		/// Unbinding a stream that isn't bound to a device is a legal no-op.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void UnbindAudioStreamsNative(SDLAudioStream** streams, int numStreams)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<SDLAudioStream**, int, void>)funcTable[329])(streams, numStreams);
			#else
			((delegate* unmanaged[Cdecl]<nint, int, void>)funcTable[329])((nint)streams, numStreams);
			#endif
		}

		/// <summary>
		/// Unbind a list of audio streams from their audio devices.<br/>
		/// The streams being unbound do not all have to be on the same device. All<br/>
		/// streams on the same device will be unbound atomically (data will stop<br/>
		/// flowing through all unbound streams on the same device at the same time).<br/>
		/// Unbinding a stream that isn't bound to a device is a legal no-op.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static void UnbindAudioStreams(SDLAudioStream** streams, int numStreams)
		{
			UnbindAudioStreamsNative(streams, numStreams);
		}

		/// <summary>
		/// Unbind a list of audio streams from their audio devices.<br/>
		/// The streams being unbound do not all have to be on the same device. All<br/>
		/// streams on the same device will be unbound atomically (data will stop<br/>
		/// flowing through all unbound streams on the same device at the same time).<br/>
		/// Unbinding a stream that isn't bound to a device is a legal no-op.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static void UnbindAudioStreams(ref SDLAudioStream* streams, int numStreams)
		{
			fixed (SDLAudioStream** pstreams = &streams)
			{
				UnbindAudioStreamsNative((SDLAudioStream**)pstreams, numStreams);
			}
		}

		/// <summary>
		/// Unbind a single audio stream from its audio device.<br/>
		/// This is a convenience function, equivalent to calling<br/>
		/// `SDL_UnbindAudioStreams(<br/>
		/// &stream<br/>
		/// , 1)`.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void UnbindAudioStreamNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<SDLAudioStream*, void>)funcTable[330])(stream);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)funcTable[330])((nint)stream);
			#endif
		}

		/// <summary>
		/// Unbind a single audio stream from its audio device.<br/>
		/// This is a convenience function, equivalent to calling<br/>
		/// `SDL_UnbindAudioStreams(<br/>
		/// &stream<br/>
		/// , 1)`.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static void UnbindAudioStream(SDLAudioStream* stream)
		{
			UnbindAudioStreamNative(stream);
		}

		/// <summary>
		/// Unbind a single audio stream from its audio device.<br/>
		/// This is a convenience function, equivalent to calling<br/>
		/// `SDL_UnbindAudioStreams(<br/>
		/// &stream<br/>
		/// , 1)`.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static void UnbindAudioStream(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				UnbindAudioStreamNative((SDLAudioStream*)pstream);
			}
		}

		/// <summary>
		/// Query an audio stream for its currently-bound device.<br/>
		/// This reports the audio device that an audio stream is currently bound to.<br/>
		/// If not bound, or invalid, this returns zero, which is not a valid device<br/>
		/// ID.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint GetAudioStreamDeviceNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, uint>)funcTable[331])(stream);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<nint, uint>)funcTable[331])((nint)stream);
			#endif
		}

		/// <summary>
		/// Query an audio stream for its currently-bound device.<br/>
		/// This reports the audio device that an audio stream is currently bound to.<br/>
		/// If not bound, or invalid, this returns zero, which is not a valid device<br/>
		/// ID.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static uint GetAudioStreamDevice(SDLAudioStream* stream)
		{
			uint ret = GetAudioStreamDeviceNative(stream);
			return ret;
		}

		/// <summary>
		/// Query an audio stream for its currently-bound device.<br/>
		/// This reports the audio device that an audio stream is currently bound to.<br/>
		/// If not bound, or invalid, this returns zero, which is not a valid device<br/>
		/// ID.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static uint GetAudioStreamDevice(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				uint ret = GetAudioStreamDeviceNative((SDLAudioStream*)pstream);
				return ret;
			}
		}

		/// <summary>
		/// Create a new audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static SDLAudioStream* CreateAudioStreamNative(SDLAudioSpec* srcSpec, SDLAudioSpec* dstSpec)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioSpec*, SDLAudioSpec*, SDLAudioStream*>)funcTable[332])(srcSpec, dstSpec);
			#else
			return (SDLAudioStream*)((delegate* unmanaged[Cdecl]<nint, nint, nint>)funcTable[332])((nint)srcSpec, (nint)dstSpec);
			#endif
		}

		/// <summary>
		/// Create a new audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static SDLAudioStream* CreateAudioStream(SDLAudioSpec* srcSpec, SDLAudioSpec* dstSpec)
		{
			SDLAudioStream* ret = CreateAudioStreamNative(srcSpec, dstSpec);
			return ret;
		}

		/// <summary>
		/// Create a new audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static SDLAudioStream* CreateAudioStream(ref SDLAudioSpec srcSpec, SDLAudioSpec* dstSpec)
		{
			fixed (SDLAudioSpec* psrcSpec = &srcSpec)
			{
				SDLAudioStream* ret = CreateAudioStreamNative((SDLAudioSpec*)psrcSpec, dstSpec);
				return ret;
			}
		}

		/// <summary>
		/// Create a new audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static SDLAudioStream* CreateAudioStream(SDLAudioSpec* srcSpec, ref SDLAudioSpec dstSpec)
		{
			fixed (SDLAudioSpec* pdstSpec = &dstSpec)
			{
				SDLAudioStream* ret = CreateAudioStreamNative(srcSpec, (SDLAudioSpec*)pdstSpec);
				return ret;
			}
		}

		/// <summary>
		/// Create a new audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static SDLAudioStream* CreateAudioStream(ref SDLAudioSpec srcSpec, ref SDLAudioSpec dstSpec)
		{
			fixed (SDLAudioSpec* psrcSpec = &srcSpec)
			{
				fixed (SDLAudioSpec* pdstSpec = &dstSpec)
				{
					SDLAudioStream* ret = CreateAudioStreamNative((SDLAudioSpec*)psrcSpec, (SDLAudioSpec*)pdstSpec);
					return ret;
				}
			}
		}

		/// <summary>
		/// Get the properties associated with an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint GetAudioStreamPropertiesNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, uint>)funcTable[333])(stream);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<nint, uint>)funcTable[333])((nint)stream);
			#endif
		}

		/// <summary>
		/// Get the properties associated with an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// </summary>
		public static uint GetAudioStreamProperties(SDLAudioStream* stream)
		{
			uint ret = GetAudioStreamPropertiesNative(stream);
			return ret;
		}

		/// <summary>
		/// Get the properties associated with an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// </summary>
		public static uint GetAudioStreamProperties(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				uint ret = GetAudioStreamPropertiesNative((SDLAudioStream*)pstream);
				return ret;
			}
		}

		/// <summary>
		/// Query the current format of an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte GetAudioStreamFormatNative(SDLAudioStream* stream, SDLAudioSpec* srcSpec, SDLAudioSpec* dstSpec)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, SDLAudioSpec*, SDLAudioSpec*, byte>)funcTable[334])(stream, srcSpec, dstSpec);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, nint, nint, byte>)funcTable[334])((nint)stream, (nint)srcSpec, (nint)dstSpec);
			#endif
		}

		/// <summary>
		/// Query the current format of an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool GetAudioStreamFormat(SDLAudioStream* stream, SDLAudioSpec* srcSpec, SDLAudioSpec* dstSpec)
		{
			byte ret = GetAudioStreamFormatNative(stream, srcSpec, dstSpec);
			return ret != 0;
		}

		/// <summary>
		/// Query the current format of an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool GetAudioStreamFormat(ref SDLAudioStream stream, SDLAudioSpec* srcSpec, SDLAudioSpec* dstSpec)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = GetAudioStreamFormatNative((SDLAudioStream*)pstream, srcSpec, dstSpec);
				return ret != 0;
			}
		}

		/// <summary>
		/// Query the current format of an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool GetAudioStreamFormat(SDLAudioStream* stream, ref SDLAudioSpec srcSpec, SDLAudioSpec* dstSpec)
		{
			fixed (SDLAudioSpec* psrcSpec = &srcSpec)
			{
				byte ret = GetAudioStreamFormatNative(stream, (SDLAudioSpec*)psrcSpec, dstSpec);
				return ret != 0;
			}
		}

		/// <summary>
		/// Query the current format of an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool GetAudioStreamFormat(ref SDLAudioStream stream, ref SDLAudioSpec srcSpec, SDLAudioSpec* dstSpec)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				fixed (SDLAudioSpec* psrcSpec = &srcSpec)
				{
					byte ret = GetAudioStreamFormatNative((SDLAudioStream*)pstream, (SDLAudioSpec*)psrcSpec, dstSpec);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Query the current format of an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool GetAudioStreamFormat(SDLAudioStream* stream, SDLAudioSpec* srcSpec, ref SDLAudioSpec dstSpec)
		{
			fixed (SDLAudioSpec* pdstSpec = &dstSpec)
			{
				byte ret = GetAudioStreamFormatNative(stream, srcSpec, (SDLAudioSpec*)pdstSpec);
				return ret != 0;
			}
		}

		/// <summary>
		/// Query the current format of an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool GetAudioStreamFormat(ref SDLAudioStream stream, SDLAudioSpec* srcSpec, ref SDLAudioSpec dstSpec)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				fixed (SDLAudioSpec* pdstSpec = &dstSpec)
				{
					byte ret = GetAudioStreamFormatNative((SDLAudioStream*)pstream, srcSpec, (SDLAudioSpec*)pdstSpec);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Query the current format of an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool GetAudioStreamFormat(SDLAudioStream* stream, ref SDLAudioSpec srcSpec, ref SDLAudioSpec dstSpec)
		{
			fixed (SDLAudioSpec* psrcSpec = &srcSpec)
			{
				fixed (SDLAudioSpec* pdstSpec = &dstSpec)
				{
					byte ret = GetAudioStreamFormatNative(stream, (SDLAudioSpec*)psrcSpec, (SDLAudioSpec*)pdstSpec);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Query the current format of an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool GetAudioStreamFormat(ref SDLAudioStream stream, ref SDLAudioSpec srcSpec, ref SDLAudioSpec dstSpec)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				fixed (SDLAudioSpec* psrcSpec = &srcSpec)
				{
					fixed (SDLAudioSpec* pdstSpec = &dstSpec)
					{
						byte ret = GetAudioStreamFormatNative((SDLAudioStream*)pstream, (SDLAudioSpec*)psrcSpec, (SDLAudioSpec*)pdstSpec);
						return ret != 0;
					}
				}
			}
		}

		/// <summary>
		/// Change the input and output formats of an audio stream.<br/>
		/// Future calls to and SDL_GetAudioStreamAvailable and SDL_GetAudioStreamData<br/>
		/// will reflect the new format, and future calls to SDL_PutAudioStreamData<br/>
		/// must provide data in the new input formats.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the format that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one format to a stream, change formats for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// If a stream is bound to a device, then the format of the side of the stream<br/>
		/// bound to a device cannot be changed (src_spec for recording devices,<br/>
		/// dst_spec for playback devices). Attempts to make a change to this side will<br/>
		/// be ignored, but this will not report an error. The other side's format can<br/>
		/// be changed.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte SetAudioStreamFormatNative(SDLAudioStream* stream, SDLAudioSpec* srcSpec, SDLAudioSpec* dstSpec)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, SDLAudioSpec*, SDLAudioSpec*, byte>)funcTable[335])(stream, srcSpec, dstSpec);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, nint, nint, byte>)funcTable[335])((nint)stream, (nint)srcSpec, (nint)dstSpec);
			#endif
		}

		/// <summary>
		/// Change the input and output formats of an audio stream.<br/>
		/// Future calls to and SDL_GetAudioStreamAvailable and SDL_GetAudioStreamData<br/>
		/// will reflect the new format, and future calls to SDL_PutAudioStreamData<br/>
		/// must provide data in the new input formats.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the format that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one format to a stream, change formats for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// If a stream is bound to a device, then the format of the side of the stream<br/>
		/// bound to a device cannot be changed (src_spec for recording devices,<br/>
		/// dst_spec for playback devices). Attempts to make a change to this side will<br/>
		/// be ignored, but this will not report an error. The other side's format can<br/>
		/// be changed.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamFormat(SDLAudioStream* stream, SDLAudioSpec* srcSpec, SDLAudioSpec* dstSpec)
		{
			byte ret = SetAudioStreamFormatNative(stream, srcSpec, dstSpec);
			return ret != 0;
		}

		/// <summary>
		/// Change the input and output formats of an audio stream.<br/>
		/// Future calls to and SDL_GetAudioStreamAvailable and SDL_GetAudioStreamData<br/>
		/// will reflect the new format, and future calls to SDL_PutAudioStreamData<br/>
		/// must provide data in the new input formats.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the format that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one format to a stream, change formats for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// If a stream is bound to a device, then the format of the side of the stream<br/>
		/// bound to a device cannot be changed (src_spec for recording devices,<br/>
		/// dst_spec for playback devices). Attempts to make a change to this side will<br/>
		/// be ignored, but this will not report an error. The other side's format can<br/>
		/// be changed.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamFormat(ref SDLAudioStream stream, SDLAudioSpec* srcSpec, SDLAudioSpec* dstSpec)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = SetAudioStreamFormatNative((SDLAudioStream*)pstream, srcSpec, dstSpec);
				return ret != 0;
			}
		}

		/// <summary>
		/// Change the input and output formats of an audio stream.<br/>
		/// Future calls to and SDL_GetAudioStreamAvailable and SDL_GetAudioStreamData<br/>
		/// will reflect the new format, and future calls to SDL_PutAudioStreamData<br/>
		/// must provide data in the new input formats.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the format that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one format to a stream, change formats for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// If a stream is bound to a device, then the format of the side of the stream<br/>
		/// bound to a device cannot be changed (src_spec for recording devices,<br/>
		/// dst_spec for playback devices). Attempts to make a change to this side will<br/>
		/// be ignored, but this will not report an error. The other side's format can<br/>
		/// be changed.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamFormat(SDLAudioStream* stream, ref SDLAudioSpec srcSpec, SDLAudioSpec* dstSpec)
		{
			fixed (SDLAudioSpec* psrcSpec = &srcSpec)
			{
				byte ret = SetAudioStreamFormatNative(stream, (SDLAudioSpec*)psrcSpec, dstSpec);
				return ret != 0;
			}
		}

		/// <summary>
		/// Change the input and output formats of an audio stream.<br/>
		/// Future calls to and SDL_GetAudioStreamAvailable and SDL_GetAudioStreamData<br/>
		/// will reflect the new format, and future calls to SDL_PutAudioStreamData<br/>
		/// must provide data in the new input formats.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the format that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one format to a stream, change formats for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// If a stream is bound to a device, then the format of the side of the stream<br/>
		/// bound to a device cannot be changed (src_spec for recording devices,<br/>
		/// dst_spec for playback devices). Attempts to make a change to this side will<br/>
		/// be ignored, but this will not report an error. The other side's format can<br/>
		/// be changed.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamFormat(ref SDLAudioStream stream, ref SDLAudioSpec srcSpec, SDLAudioSpec* dstSpec)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				fixed (SDLAudioSpec* psrcSpec = &srcSpec)
				{
					byte ret = SetAudioStreamFormatNative((SDLAudioStream*)pstream, (SDLAudioSpec*)psrcSpec, dstSpec);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Change the input and output formats of an audio stream.<br/>
		/// Future calls to and SDL_GetAudioStreamAvailable and SDL_GetAudioStreamData<br/>
		/// will reflect the new format, and future calls to SDL_PutAudioStreamData<br/>
		/// must provide data in the new input formats.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the format that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one format to a stream, change formats for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// If a stream is bound to a device, then the format of the side of the stream<br/>
		/// bound to a device cannot be changed (src_spec for recording devices,<br/>
		/// dst_spec for playback devices). Attempts to make a change to this side will<br/>
		/// be ignored, but this will not report an error. The other side's format can<br/>
		/// be changed.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamFormat(SDLAudioStream* stream, SDLAudioSpec* srcSpec, ref SDLAudioSpec dstSpec)
		{
			fixed (SDLAudioSpec* pdstSpec = &dstSpec)
			{
				byte ret = SetAudioStreamFormatNative(stream, srcSpec, (SDLAudioSpec*)pdstSpec);
				return ret != 0;
			}
		}

		/// <summary>
		/// Change the input and output formats of an audio stream.<br/>
		/// Future calls to and SDL_GetAudioStreamAvailable and SDL_GetAudioStreamData<br/>
		/// will reflect the new format, and future calls to SDL_PutAudioStreamData<br/>
		/// must provide data in the new input formats.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the format that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one format to a stream, change formats for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// If a stream is bound to a device, then the format of the side of the stream<br/>
		/// bound to a device cannot be changed (src_spec for recording devices,<br/>
		/// dst_spec for playback devices). Attempts to make a change to this side will<br/>
		/// be ignored, but this will not report an error. The other side's format can<br/>
		/// be changed.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamFormat(ref SDLAudioStream stream, SDLAudioSpec* srcSpec, ref SDLAudioSpec dstSpec)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				fixed (SDLAudioSpec* pdstSpec = &dstSpec)
				{
					byte ret = SetAudioStreamFormatNative((SDLAudioStream*)pstream, srcSpec, (SDLAudioSpec*)pdstSpec);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Change the input and output formats of an audio stream.<br/>
		/// Future calls to and SDL_GetAudioStreamAvailable and SDL_GetAudioStreamData<br/>
		/// will reflect the new format, and future calls to SDL_PutAudioStreamData<br/>
		/// must provide data in the new input formats.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the format that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one format to a stream, change formats for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// If a stream is bound to a device, then the format of the side of the stream<br/>
		/// bound to a device cannot be changed (src_spec for recording devices,<br/>
		/// dst_spec for playback devices). Attempts to make a change to this side will<br/>
		/// be ignored, but this will not report an error. The other side's format can<br/>
		/// be changed.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamFormat(SDLAudioStream* stream, ref SDLAudioSpec srcSpec, ref SDLAudioSpec dstSpec)
		{
			fixed (SDLAudioSpec* psrcSpec = &srcSpec)
			{
				fixed (SDLAudioSpec* pdstSpec = &dstSpec)
				{
					byte ret = SetAudioStreamFormatNative(stream, (SDLAudioSpec*)psrcSpec, (SDLAudioSpec*)pdstSpec);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Change the input and output formats of an audio stream.<br/>
		/// Future calls to and SDL_GetAudioStreamAvailable and SDL_GetAudioStreamData<br/>
		/// will reflect the new format, and future calls to SDL_PutAudioStreamData<br/>
		/// must provide data in the new input formats.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the format that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one format to a stream, change formats for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// If a stream is bound to a device, then the format of the side of the stream<br/>
		/// bound to a device cannot be changed (src_spec for recording devices,<br/>
		/// dst_spec for playback devices). Attempts to make a change to this side will<br/>
		/// be ignored, but this will not report an error. The other side's format can<br/>
		/// be changed.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamFormat(ref SDLAudioStream stream, ref SDLAudioSpec srcSpec, ref SDLAudioSpec dstSpec)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				fixed (SDLAudioSpec* psrcSpec = &srcSpec)
				{
					fixed (SDLAudioSpec* pdstSpec = &dstSpec)
					{
						byte ret = SetAudioStreamFormatNative((SDLAudioStream*)pstream, (SDLAudioSpec*)psrcSpec, (SDLAudioSpec*)pdstSpec);
						return ret != 0;
					}
				}
			}
		}

		/// <summary>
		/// Get the frequency ratio of an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static float GetAudioStreamFrequencyRatioNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, float>)funcTable[336])(stream);
			#else
			return (float)((delegate* unmanaged[Cdecl]<nint, float>)funcTable[336])((nint)stream);
			#endif
		}

		/// <summary>
		/// Get the frequency ratio of an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static float GetAudioStreamFrequencyRatio(SDLAudioStream* stream)
		{
			float ret = GetAudioStreamFrequencyRatioNative(stream);
			return ret;
		}

		/// <summary>
		/// Get the frequency ratio of an audio stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static float GetAudioStreamFrequencyRatio(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				float ret = GetAudioStreamFrequencyRatioNative((SDLAudioStream*)pstream);
				return ret;
			}
		}

		/// <summary>
		/// Change the frequency ratio of an audio stream.<br/>
		/// The frequency ratio is used to adjust the rate at which input data is<br/>
		/// consumed. Changing this effectively modifies the speed and pitch of the<br/>
		/// audio. A value greater than 1.0 will play the audio faster, and at a higher<br/>
		/// pitch. A value less than 1.0 will play the audio slower, and at a lower<br/>
		/// pitch.<br/>
		/// This is applied during SDL_GetAudioStreamData, and can be continuously<br/>
		/// changed to create various effects.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte SetAudioStreamFrequencyRatioNative(SDLAudioStream* stream, float ratio)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, float, byte>)funcTable[337])(stream, ratio);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, float, byte>)funcTable[337])((nint)stream, ratio);
			#endif
		}

		/// <summary>
		/// Change the frequency ratio of an audio stream.<br/>
		/// The frequency ratio is used to adjust the rate at which input data is<br/>
		/// consumed. Changing this effectively modifies the speed and pitch of the<br/>
		/// audio. A value greater than 1.0 will play the audio faster, and at a higher<br/>
		/// pitch. A value less than 1.0 will play the audio slower, and at a lower<br/>
		/// pitch.<br/>
		/// This is applied during SDL_GetAudioStreamData, and can be continuously<br/>
		/// changed to create various effects.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamFrequencyRatio(SDLAudioStream* stream, float ratio)
		{
			byte ret = SetAudioStreamFrequencyRatioNative(stream, ratio);
			return ret != 0;
		}

		/// <summary>
		/// Change the frequency ratio of an audio stream.<br/>
		/// The frequency ratio is used to adjust the rate at which input data is<br/>
		/// consumed. Changing this effectively modifies the speed and pitch of the<br/>
		/// audio. A value greater than 1.0 will play the audio faster, and at a higher<br/>
		/// pitch. A value less than 1.0 will play the audio slower, and at a lower<br/>
		/// pitch.<br/>
		/// This is applied during SDL_GetAudioStreamData, and can be continuously<br/>
		/// changed to create various effects.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamFrequencyRatio(ref SDLAudioStream stream, float ratio)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = SetAudioStreamFrequencyRatioNative((SDLAudioStream*)pstream, ratio);
				return ret != 0;
			}
		}

		/// <summary>
		/// Get the gain of an audio stream.<br/>
		/// The gain of a stream is its volume; a larger gain means a louder output,<br/>
		/// with a gain of zero being silence.<br/>
		/// Audio streams default to a gain of 1.0f (no change in output).<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static float GetAudioStreamGainNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, float>)funcTable[338])(stream);
			#else
			return (float)((delegate* unmanaged[Cdecl]<nint, float>)funcTable[338])((nint)stream);
			#endif
		}

		/// <summary>
		/// Get the gain of an audio stream.<br/>
		/// The gain of a stream is its volume; a larger gain means a louder output,<br/>
		/// with a gain of zero being silence.<br/>
		/// Audio streams default to a gain of 1.0f (no change in output).<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static float GetAudioStreamGain(SDLAudioStream* stream)
		{
			float ret = GetAudioStreamGainNative(stream);
			return ret;
		}

		/// <summary>
		/// Get the gain of an audio stream.<br/>
		/// The gain of a stream is its volume; a larger gain means a louder output,<br/>
		/// with a gain of zero being silence.<br/>
		/// Audio streams default to a gain of 1.0f (no change in output).<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static float GetAudioStreamGain(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				float ret = GetAudioStreamGainNative((SDLAudioStream*)pstream);
				return ret;
			}
		}

		/// <summary>
		/// Change the gain of an audio stream.<br/>
		/// The gain of a stream is its volume; a larger gain means a louder output,<br/>
		/// with a gain of zero being silence.<br/>
		/// Audio streams default to a gain of 1.0f (no change in output).<br/>
		/// This is applied during SDL_GetAudioStreamData, and can be continuously<br/>
		/// changed to create various effects.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte SetAudioStreamGainNative(SDLAudioStream* stream, float gain)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, float, byte>)funcTable[339])(stream, gain);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, float, byte>)funcTable[339])((nint)stream, gain);
			#endif
		}

		/// <summary>
		/// Change the gain of an audio stream.<br/>
		/// The gain of a stream is its volume; a larger gain means a louder output,<br/>
		/// with a gain of zero being silence.<br/>
		/// Audio streams default to a gain of 1.0f (no change in output).<br/>
		/// This is applied during SDL_GetAudioStreamData, and can be continuously<br/>
		/// changed to create various effects.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamGain(SDLAudioStream* stream, float gain)
		{
			byte ret = SetAudioStreamGainNative(stream, gain);
			return ret != 0;
		}

		/// <summary>
		/// Change the gain of an audio stream.<br/>
		/// The gain of a stream is its volume; a larger gain means a louder output,<br/>
		/// with a gain of zero being silence.<br/>
		/// Audio streams default to a gain of 1.0f (no change in output).<br/>
		/// This is applied during SDL_GetAudioStreamData, and can be continuously<br/>
		/// changed to create various effects.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamGain(ref SDLAudioStream stream, float gain)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = SetAudioStreamGainNative((SDLAudioStream*)pstream, gain);
				return ret != 0;
			}
		}

		/// <summary>
		/// Get the current input channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// Audio streams default to no remapping applied. This is represented by<br/>
		/// returning NULL, and does not signify an error.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static int* GetAudioStreamInputChannelMapNative(SDLAudioStream* stream, int* count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, int*, int*>)funcTable[340])(stream, count);
			#else
			return (int*)((delegate* unmanaged[Cdecl]<nint, nint, nint>)funcTable[340])((nint)stream, (nint)count);
			#endif
		}

		/// <summary>
		/// Get the current input channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// Audio streams default to no remapping applied. This is represented by<br/>
		/// returning NULL, and does not signify an error.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int* GetAudioStreamInputChannelMap(SDLAudioStream* stream, int* count)
		{
			int* ret = GetAudioStreamInputChannelMapNative(stream, count);
			return ret;
		}

		/// <summary>
		/// Get the current input channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// Audio streams default to no remapping applied. This is represented by<br/>
		/// returning NULL, and does not signify an error.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int* GetAudioStreamInputChannelMap(ref SDLAudioStream stream, int* count)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				int* ret = GetAudioStreamInputChannelMapNative((SDLAudioStream*)pstream, count);
				return ret;
			}
		}

		/// <summary>
		/// Get the current input channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// Audio streams default to no remapping applied. This is represented by<br/>
		/// returning NULL, and does not signify an error.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int* GetAudioStreamInputChannelMap(SDLAudioStream* stream, ref int count)
		{
			fixed (int* pcount = &count)
			{
				int* ret = GetAudioStreamInputChannelMapNative(stream, (int*)pcount);
				return ret;
			}
		}

		/// <summary>
		/// Get the current input channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// Audio streams default to no remapping applied. This is represented by<br/>
		/// returning NULL, and does not signify an error.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int* GetAudioStreamInputChannelMap(ref SDLAudioStream stream, ref int count)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				fixed (int* pcount = &count)
				{
					int* ret = GetAudioStreamInputChannelMapNative((SDLAudioStream*)pstream, (int*)pcount);
					return ret;
				}
			}
		}

		/// <summary>
		/// Get the current output channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// Audio streams default to no remapping applied. This is represented by<br/>
		/// returning NULL, and does not signify an error.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static int* GetAudioStreamOutputChannelMapNative(SDLAudioStream* stream, int* count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, int*, int*>)funcTable[341])(stream, count);
			#else
			return (int*)((delegate* unmanaged[Cdecl]<nint, nint, nint>)funcTable[341])((nint)stream, (nint)count);
			#endif
		}

		/// <summary>
		/// Get the current output channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// Audio streams default to no remapping applied. This is represented by<br/>
		/// returning NULL, and does not signify an error.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int* GetAudioStreamOutputChannelMap(SDLAudioStream* stream, int* count)
		{
			int* ret = GetAudioStreamOutputChannelMapNative(stream, count);
			return ret;
		}

		/// <summary>
		/// Get the current output channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// Audio streams default to no remapping applied. This is represented by<br/>
		/// returning NULL, and does not signify an error.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int* GetAudioStreamOutputChannelMap(ref SDLAudioStream stream, int* count)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				int* ret = GetAudioStreamOutputChannelMapNative((SDLAudioStream*)pstream, count);
				return ret;
			}
		}

		/// <summary>
		/// Get the current output channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// Audio streams default to no remapping applied. This is represented by<br/>
		/// returning NULL, and does not signify an error.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int* GetAudioStreamOutputChannelMap(SDLAudioStream* stream, ref int count)
		{
			fixed (int* pcount = &count)
			{
				int* ret = GetAudioStreamOutputChannelMapNative(stream, (int*)pcount);
				return ret;
			}
		}

		/// <summary>
		/// Get the current output channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// Audio streams default to no remapping applied. This is represented by<br/>
		/// returning NULL, and does not signify an error.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int* GetAudioStreamOutputChannelMap(ref SDLAudioStream stream, ref int count)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				fixed (int* pcount = &count)
				{
					int* ret = GetAudioStreamOutputChannelMapNative((SDLAudioStream*)pstream, (int*)pcount);
					return ret;
				}
			}
		}

		/// <summary>
		/// Set the current input channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// The input channel map reorders data that is added to a stream via<br/>
		/// SDL_PutAudioStreamData. Future calls to SDL_PutAudioStreamData must provide<br/>
		/// data in the new channel order.<br/>
		/// Each item in the array represents an input channel, and its value is the<br/>
		/// channel that it should be remapped to. To reverse a stereo signal's left<br/>
		/// and right values, you'd have an array of `{ 1, 0 }`. It is legal to remap<br/>
		/// multiple channels to the same thing, so `{ 1, 1 }` would duplicate the<br/>
		/// right channel to both channels of a stereo signal. An element in the<br/>
		/// channel map set to -1 instead of a valid channel will mute that channel,<br/>
		/// setting it to a silence value.<br/>
		/// You cannot change the number of channels through a channel map, just<br/>
		/// reorder/mute them.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the order that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one order to a stream, change orders for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// Audio streams default to no remapping applied. Passing a NULL channel map<br/>
		/// is legal, and turns off remapping.<br/>
		/// SDL will copy the channel map; the caller does not have to save this array<br/>
		/// after this call.<br/>
		/// If `count` is not equal to the current number of channels in the audio<br/>
		/// stream's format, this will fail. This is a safety measure to make sure a<br/>
		/// race condition hasn't changed the format while this call is setting the<br/>
		/// channel map.<br/>
		/// Unlike attempting to change the stream's format, the input channel map on a<br/>
		/// stream bound to a recording device is permitted to change at any time; any<br/>
		/// data added to the stream from the device after this call will have the new<br/>
		/// mapping, but previously-added data will still have the prior mapping.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running. Don't change the<br/>
		/// stream's format to have a different number of channels from a<br/>
		/// a different thread at the same time, though!<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte SetAudioStreamInputChannelMapNative(SDLAudioStream* stream, int* chmap, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, int*, int, byte>)funcTable[342])(stream, chmap, count);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, nint, int, byte>)funcTable[342])((nint)stream, (nint)chmap, count);
			#endif
		}

		/// <summary>
		/// Set the current input channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// The input channel map reorders data that is added to a stream via<br/>
		/// SDL_PutAudioStreamData. Future calls to SDL_PutAudioStreamData must provide<br/>
		/// data in the new channel order.<br/>
		/// Each item in the array represents an input channel, and its value is the<br/>
		/// channel that it should be remapped to. To reverse a stereo signal's left<br/>
		/// and right values, you'd have an array of `{ 1, 0 }`. It is legal to remap<br/>
		/// multiple channels to the same thing, so `{ 1, 1 }` would duplicate the<br/>
		/// right channel to both channels of a stereo signal. An element in the<br/>
		/// channel map set to -1 instead of a valid channel will mute that channel,<br/>
		/// setting it to a silence value.<br/>
		/// You cannot change the number of channels through a channel map, just<br/>
		/// reorder/mute them.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the order that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one order to a stream, change orders for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// Audio streams default to no remapping applied. Passing a NULL channel map<br/>
		/// is legal, and turns off remapping.<br/>
		/// SDL will copy the channel map; the caller does not have to save this array<br/>
		/// after this call.<br/>
		/// If `count` is not equal to the current number of channels in the audio<br/>
		/// stream's format, this will fail. This is a safety measure to make sure a<br/>
		/// race condition hasn't changed the format while this call is setting the<br/>
		/// channel map.<br/>
		/// Unlike attempting to change the stream's format, the input channel map on a<br/>
		/// stream bound to a recording device is permitted to change at any time; any<br/>
		/// data added to the stream from the device after this call will have the new<br/>
		/// mapping, but previously-added data will still have the prior mapping.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running. Don't change the<br/>
		/// stream's format to have a different number of channels from a<br/>
		/// a different thread at the same time, though!<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamInputChannelMap(SDLAudioStream* stream, int* chmap, int count)
		{
			byte ret = SetAudioStreamInputChannelMapNative(stream, chmap, count);
			return ret != 0;
		}

		/// <summary>
		/// Set the current input channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// The input channel map reorders data that is added to a stream via<br/>
		/// SDL_PutAudioStreamData. Future calls to SDL_PutAudioStreamData must provide<br/>
		/// data in the new channel order.<br/>
		/// Each item in the array represents an input channel, and its value is the<br/>
		/// channel that it should be remapped to. To reverse a stereo signal's left<br/>
		/// and right values, you'd have an array of `{ 1, 0 }`. It is legal to remap<br/>
		/// multiple channels to the same thing, so `{ 1, 1 }` would duplicate the<br/>
		/// right channel to both channels of a stereo signal. An element in the<br/>
		/// channel map set to -1 instead of a valid channel will mute that channel,<br/>
		/// setting it to a silence value.<br/>
		/// You cannot change the number of channels through a channel map, just<br/>
		/// reorder/mute them.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the order that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one order to a stream, change orders for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// Audio streams default to no remapping applied. Passing a NULL channel map<br/>
		/// is legal, and turns off remapping.<br/>
		/// SDL will copy the channel map; the caller does not have to save this array<br/>
		/// after this call.<br/>
		/// If `count` is not equal to the current number of channels in the audio<br/>
		/// stream's format, this will fail. This is a safety measure to make sure a<br/>
		/// race condition hasn't changed the format while this call is setting the<br/>
		/// channel map.<br/>
		/// Unlike attempting to change the stream's format, the input channel map on a<br/>
		/// stream bound to a recording device is permitted to change at any time; any<br/>
		/// data added to the stream from the device after this call will have the new<br/>
		/// mapping, but previously-added data will still have the prior mapping.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running. Don't change the<br/>
		/// stream's format to have a different number of channels from a<br/>
		/// a different thread at the same time, though!<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamInputChannelMap(ref SDLAudioStream stream, int* chmap, int count)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = SetAudioStreamInputChannelMapNative((SDLAudioStream*)pstream, chmap, count);
				return ret != 0;
			}
		}

		/// <summary>
		/// Set the current input channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// The input channel map reorders data that is added to a stream via<br/>
		/// SDL_PutAudioStreamData. Future calls to SDL_PutAudioStreamData must provide<br/>
		/// data in the new channel order.<br/>
		/// Each item in the array represents an input channel, and its value is the<br/>
		/// channel that it should be remapped to. To reverse a stereo signal's left<br/>
		/// and right values, you'd have an array of `{ 1, 0 }`. It is legal to remap<br/>
		/// multiple channels to the same thing, so `{ 1, 1 }` would duplicate the<br/>
		/// right channel to both channels of a stereo signal. An element in the<br/>
		/// channel map set to -1 instead of a valid channel will mute that channel,<br/>
		/// setting it to a silence value.<br/>
		/// You cannot change the number of channels through a channel map, just<br/>
		/// reorder/mute them.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the order that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one order to a stream, change orders for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// Audio streams default to no remapping applied. Passing a NULL channel map<br/>
		/// is legal, and turns off remapping.<br/>
		/// SDL will copy the channel map; the caller does not have to save this array<br/>
		/// after this call.<br/>
		/// If `count` is not equal to the current number of channels in the audio<br/>
		/// stream's format, this will fail. This is a safety measure to make sure a<br/>
		/// race condition hasn't changed the format while this call is setting the<br/>
		/// channel map.<br/>
		/// Unlike attempting to change the stream's format, the input channel map on a<br/>
		/// stream bound to a recording device is permitted to change at any time; any<br/>
		/// data added to the stream from the device after this call will have the new<br/>
		/// mapping, but previously-added data will still have the prior mapping.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running. Don't change the<br/>
		/// stream's format to have a different number of channels from a<br/>
		/// a different thread at the same time, though!<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamInputChannelMap(SDLAudioStream* stream, ref int chmap, int count)
		{
			fixed (int* pchmap = &chmap)
			{
				byte ret = SetAudioStreamInputChannelMapNative(stream, (int*)pchmap, count);
				return ret != 0;
			}
		}

		/// <summary>
		/// Set the current input channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// The input channel map reorders data that is added to a stream via<br/>
		/// SDL_PutAudioStreamData. Future calls to SDL_PutAudioStreamData must provide<br/>
		/// data in the new channel order.<br/>
		/// Each item in the array represents an input channel, and its value is the<br/>
		/// channel that it should be remapped to. To reverse a stereo signal's left<br/>
		/// and right values, you'd have an array of `{ 1, 0 }`. It is legal to remap<br/>
		/// multiple channels to the same thing, so `{ 1, 1 }` would duplicate the<br/>
		/// right channel to both channels of a stereo signal. An element in the<br/>
		/// channel map set to -1 instead of a valid channel will mute that channel,<br/>
		/// setting it to a silence value.<br/>
		/// You cannot change the number of channels through a channel map, just<br/>
		/// reorder/mute them.<br/>
		/// Data that was previously queued in the stream will still be operated on in<br/>
		/// the order that was current when it was added, which is to say you can put<br/>
		/// the end of a sound file in one order to a stream, change orders for the<br/>
		/// next sound file, and start putting that new data while the previous sound<br/>
		/// file is still queued, and everything will still play back correctly.<br/>
		/// Audio streams default to no remapping applied. Passing a NULL channel map<br/>
		/// is legal, and turns off remapping.<br/>
		/// SDL will copy the channel map; the caller does not have to save this array<br/>
		/// after this call.<br/>
		/// If `count` is not equal to the current number of channels in the audio<br/>
		/// stream's format, this will fail. This is a safety measure to make sure a<br/>
		/// race condition hasn't changed the format while this call is setting the<br/>
		/// channel map.<br/>
		/// Unlike attempting to change the stream's format, the input channel map on a<br/>
		/// stream bound to a recording device is permitted to change at any time; any<br/>
		/// data added to the stream from the device after this call will have the new<br/>
		/// mapping, but previously-added data will still have the prior mapping.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running. Don't change the<br/>
		/// stream's format to have a different number of channels from a<br/>
		/// a different thread at the same time, though!<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamInputChannelMap(ref SDLAudioStream stream, ref int chmap, int count)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				fixed (int* pchmap = &chmap)
				{
					byte ret = SetAudioStreamInputChannelMapNative((SDLAudioStream*)pstream, (int*)pchmap, count);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Set the current output channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// The output channel map reorders data that leaving a stream via<br/>
		/// SDL_GetAudioStreamData.<br/>
		/// Each item in the array represents an input channel, and its value is the<br/>
		/// channel that it should be remapped to. To reverse a stereo signal's left<br/>
		/// and right values, you'd have an array of `{ 1, 0 }`. It is legal to remap<br/>
		/// multiple channels to the same thing, so `{ 1, 1 }` would duplicate the<br/>
		/// right channel to both channels of a stereo signal. An element in the<br/>
		/// channel map set to -1 instead of a valid channel will mute that channel,<br/>
		/// setting it to a silence value.<br/>
		/// You cannot change the number of channels through a channel map, just<br/>
		/// reorder/mute them.<br/>
		/// The output channel map can be changed at any time, as output remapping is<br/>
		/// applied during SDL_GetAudioStreamData.<br/>
		/// Audio streams default to no remapping applied. Passing a NULL channel map<br/>
		/// is legal, and turns off remapping.<br/>
		/// SDL will copy the channel map; the caller does not have to save this array<br/>
		/// after this call.<br/>
		/// If `count` is not equal to the current number of channels in the audio<br/>
		/// stream's format, this will fail. This is a safety measure to make sure a<br/>
		/// race condition hasn't changed the format while this call is setting the<br/>
		/// channel map.<br/>
		/// Unlike attempting to change the stream's format, the output channel map on<br/>
		/// a stream bound to a recording device is permitted to change at any time;<br/>
		/// any data added to the stream after this call will have the new mapping, but<br/>
		/// previously-added data will still have the prior mapping. When the channel<br/>
		/// map doesn't match the hardware's channel layout, SDL will convert the data<br/>
		/// before feeding it to the device for playback.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running. Don't change the<br/>
		/// stream's format to have a different number of channels from a<br/>
		/// a different thread at the same time, though!<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte SetAudioStreamOutputChannelMapNative(SDLAudioStream* stream, int* chmap, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, int*, int, byte>)funcTable[343])(stream, chmap, count);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, nint, int, byte>)funcTable[343])((nint)stream, (nint)chmap, count);
			#endif
		}

		/// <summary>
		/// Set the current output channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// The output channel map reorders data that leaving a stream via<br/>
		/// SDL_GetAudioStreamData.<br/>
		/// Each item in the array represents an input channel, and its value is the<br/>
		/// channel that it should be remapped to. To reverse a stereo signal's left<br/>
		/// and right values, you'd have an array of `{ 1, 0 }`. It is legal to remap<br/>
		/// multiple channels to the same thing, so `{ 1, 1 }` would duplicate the<br/>
		/// right channel to both channels of a stereo signal. An element in the<br/>
		/// channel map set to -1 instead of a valid channel will mute that channel,<br/>
		/// setting it to a silence value.<br/>
		/// You cannot change the number of channels through a channel map, just<br/>
		/// reorder/mute them.<br/>
		/// The output channel map can be changed at any time, as output remapping is<br/>
		/// applied during SDL_GetAudioStreamData.<br/>
		/// Audio streams default to no remapping applied. Passing a NULL channel map<br/>
		/// is legal, and turns off remapping.<br/>
		/// SDL will copy the channel map; the caller does not have to save this array<br/>
		/// after this call.<br/>
		/// If `count` is not equal to the current number of channels in the audio<br/>
		/// stream's format, this will fail. This is a safety measure to make sure a<br/>
		/// race condition hasn't changed the format while this call is setting the<br/>
		/// channel map.<br/>
		/// Unlike attempting to change the stream's format, the output channel map on<br/>
		/// a stream bound to a recording device is permitted to change at any time;<br/>
		/// any data added to the stream after this call will have the new mapping, but<br/>
		/// previously-added data will still have the prior mapping. When the channel<br/>
		/// map doesn't match the hardware's channel layout, SDL will convert the data<br/>
		/// before feeding it to the device for playback.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running. Don't change the<br/>
		/// stream's format to have a different number of channels from a<br/>
		/// a different thread at the same time, though!<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamOutputChannelMap(SDLAudioStream* stream, int* chmap, int count)
		{
			byte ret = SetAudioStreamOutputChannelMapNative(stream, chmap, count);
			return ret != 0;
		}

		/// <summary>
		/// Set the current output channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// The output channel map reorders data that leaving a stream via<br/>
		/// SDL_GetAudioStreamData.<br/>
		/// Each item in the array represents an input channel, and its value is the<br/>
		/// channel that it should be remapped to. To reverse a stereo signal's left<br/>
		/// and right values, you'd have an array of `{ 1, 0 }`. It is legal to remap<br/>
		/// multiple channels to the same thing, so `{ 1, 1 }` would duplicate the<br/>
		/// right channel to both channels of a stereo signal. An element in the<br/>
		/// channel map set to -1 instead of a valid channel will mute that channel,<br/>
		/// setting it to a silence value.<br/>
		/// You cannot change the number of channels through a channel map, just<br/>
		/// reorder/mute them.<br/>
		/// The output channel map can be changed at any time, as output remapping is<br/>
		/// applied during SDL_GetAudioStreamData.<br/>
		/// Audio streams default to no remapping applied. Passing a NULL channel map<br/>
		/// is legal, and turns off remapping.<br/>
		/// SDL will copy the channel map; the caller does not have to save this array<br/>
		/// after this call.<br/>
		/// If `count` is not equal to the current number of channels in the audio<br/>
		/// stream's format, this will fail. This is a safety measure to make sure a<br/>
		/// race condition hasn't changed the format while this call is setting the<br/>
		/// channel map.<br/>
		/// Unlike attempting to change the stream's format, the output channel map on<br/>
		/// a stream bound to a recording device is permitted to change at any time;<br/>
		/// any data added to the stream after this call will have the new mapping, but<br/>
		/// previously-added data will still have the prior mapping. When the channel<br/>
		/// map doesn't match the hardware's channel layout, SDL will convert the data<br/>
		/// before feeding it to the device for playback.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running. Don't change the<br/>
		/// stream's format to have a different number of channels from a<br/>
		/// a different thread at the same time, though!<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamOutputChannelMap(ref SDLAudioStream stream, int* chmap, int count)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = SetAudioStreamOutputChannelMapNative((SDLAudioStream*)pstream, chmap, count);
				return ret != 0;
			}
		}

		/// <summary>
		/// Set the current output channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// The output channel map reorders data that leaving a stream via<br/>
		/// SDL_GetAudioStreamData.<br/>
		/// Each item in the array represents an input channel, and its value is the<br/>
		/// channel that it should be remapped to. To reverse a stereo signal's left<br/>
		/// and right values, you'd have an array of `{ 1, 0 }`. It is legal to remap<br/>
		/// multiple channels to the same thing, so `{ 1, 1 }` would duplicate the<br/>
		/// right channel to both channels of a stereo signal. An element in the<br/>
		/// channel map set to -1 instead of a valid channel will mute that channel,<br/>
		/// setting it to a silence value.<br/>
		/// You cannot change the number of channels through a channel map, just<br/>
		/// reorder/mute them.<br/>
		/// The output channel map can be changed at any time, as output remapping is<br/>
		/// applied during SDL_GetAudioStreamData.<br/>
		/// Audio streams default to no remapping applied. Passing a NULL channel map<br/>
		/// is legal, and turns off remapping.<br/>
		/// SDL will copy the channel map; the caller does not have to save this array<br/>
		/// after this call.<br/>
		/// If `count` is not equal to the current number of channels in the audio<br/>
		/// stream's format, this will fail. This is a safety measure to make sure a<br/>
		/// race condition hasn't changed the format while this call is setting the<br/>
		/// channel map.<br/>
		/// Unlike attempting to change the stream's format, the output channel map on<br/>
		/// a stream bound to a recording device is permitted to change at any time;<br/>
		/// any data added to the stream after this call will have the new mapping, but<br/>
		/// previously-added data will still have the prior mapping. When the channel<br/>
		/// map doesn't match the hardware's channel layout, SDL will convert the data<br/>
		/// before feeding it to the device for playback.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running. Don't change the<br/>
		/// stream's format to have a different number of channels from a<br/>
		/// a different thread at the same time, though!<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamOutputChannelMap(SDLAudioStream* stream, ref int chmap, int count)
		{
			fixed (int* pchmap = &chmap)
			{
				byte ret = SetAudioStreamOutputChannelMapNative(stream, (int*)pchmap, count);
				return ret != 0;
			}
		}

		/// <summary>
		/// Set the current output channel map of an audio stream.<br/>
		/// Channel maps are optional; most things do not need them, instead passing<br/>
		/// data in the [order that SDL expects](CategoryAudio#channel-layouts).<br/>
		/// The output channel map reorders data that leaving a stream via<br/>
		/// SDL_GetAudioStreamData.<br/>
		/// Each item in the array represents an input channel, and its value is the<br/>
		/// channel that it should be remapped to. To reverse a stereo signal's left<br/>
		/// and right values, you'd have an array of `{ 1, 0 }`. It is legal to remap<br/>
		/// multiple channels to the same thing, so `{ 1, 1 }` would duplicate the<br/>
		/// right channel to both channels of a stereo signal. An element in the<br/>
		/// channel map set to -1 instead of a valid channel will mute that channel,<br/>
		/// setting it to a silence value.<br/>
		/// You cannot change the number of channels through a channel map, just<br/>
		/// reorder/mute them.<br/>
		/// The output channel map can be changed at any time, as output remapping is<br/>
		/// applied during SDL_GetAudioStreamData.<br/>
		/// Audio streams default to no remapping applied. Passing a NULL channel map<br/>
		/// is legal, and turns off remapping.<br/>
		/// SDL will copy the channel map; the caller does not have to save this array<br/>
		/// after this call.<br/>
		/// If `count` is not equal to the current number of channels in the audio<br/>
		/// stream's format, this will fail. This is a safety measure to make sure a<br/>
		/// race condition hasn't changed the format while this call is setting the<br/>
		/// channel map.<br/>
		/// Unlike attempting to change the stream's format, the output channel map on<br/>
		/// a stream bound to a recording device is permitted to change at any time;<br/>
		/// any data added to the stream after this call will have the new mapping, but<br/>
		/// previously-added data will still have the prior mapping. When the channel<br/>
		/// map doesn't match the hardware's channel layout, SDL will convert the data<br/>
		/// before feeding it to the device for playback.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, as it holds<br/>
		/// a stream-specific mutex while running. Don't change the<br/>
		/// stream's format to have a different number of channels from a<br/>
		/// a different thread at the same time, though!<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamOutputChannelMap(ref SDLAudioStream stream, ref int chmap, int count)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				fixed (int* pchmap = &chmap)
				{
					byte ret = SetAudioStreamOutputChannelMapNative((SDLAudioStream*)pstream, (int*)pchmap, count);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Add data to the stream.<br/>
		/// This data must match the format/channels/samplerate specified in the latest<br/>
		/// call to SDL_SetAudioStreamFormat, or the format specified when creating the<br/>
		/// stream if it hasn't been changed.<br/>
		/// Note that this call simply copies the unconverted data for later. This is<br/>
		/// different than SDL2, where data was converted during the Put call and the<br/>
		/// Get call would just dequeue the previously-converted data.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, but if the<br/>
		/// stream has a callback set, the caller might need to manage<br/>
		/// extra locking.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte PutAudioStreamDataNative(SDLAudioStream* stream, void* buf, int len)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, void*, int, byte>)funcTable[344])(stream, buf, len);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, nint, int, byte>)funcTable[344])((nint)stream, (nint)buf, len);
			#endif
		}

		/// <summary>
		/// Add data to the stream.<br/>
		/// This data must match the format/channels/samplerate specified in the latest<br/>
		/// call to SDL_SetAudioStreamFormat, or the format specified when creating the<br/>
		/// stream if it hasn't been changed.<br/>
		/// Note that this call simply copies the unconverted data for later. This is<br/>
		/// different than SDL2, where data was converted during the Put call and the<br/>
		/// Get call would just dequeue the previously-converted data.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, but if the<br/>
		/// stream has a callback set, the caller might need to manage<br/>
		/// extra locking.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool PutAudioStreamData(SDLAudioStream* stream, void* buf, int len)
		{
			byte ret = PutAudioStreamDataNative(stream, buf, len);
			return ret != 0;
		}

		/// <summary>
		/// Add data to the stream.<br/>
		/// This data must match the format/channels/samplerate specified in the latest<br/>
		/// call to SDL_SetAudioStreamFormat, or the format specified when creating the<br/>
		/// stream if it hasn't been changed.<br/>
		/// Note that this call simply copies the unconverted data for later. This is<br/>
		/// different than SDL2, where data was converted during the Put call and the<br/>
		/// Get call would just dequeue the previously-converted data.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, but if the<br/>
		/// stream has a callback set, the caller might need to manage<br/>
		/// extra locking.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool PutAudioStreamData(ref SDLAudioStream stream, void* buf, int len)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = PutAudioStreamDataNative((SDLAudioStream*)pstream, buf, len);
				return ret != 0;
			}
		}

		/// <summary>
		/// Get converted/resampled data from the stream.<br/>
		/// The input/output data format/channels/samplerate is specified when creating<br/>
		/// the stream, and can be changed after creation by calling<br/>
		/// SDL_SetAudioStreamFormat.<br/>
		/// Note that any conversion and resampling necessary is done during this call,<br/>
		/// and SDL_PutAudioStreamData simply queues unconverted data for later. This<br/>
		/// is different than SDL2, where that work was done while inputting new data<br/>
		/// to the stream and requesting the output just copied the converted data.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, but if the<br/>
		/// stream has a callback set, the caller might need to manage<br/>
		/// extra locking.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static int GetAudioStreamDataNative(SDLAudioStream* stream, void* buf, int len)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, void*, int, int>)funcTable[345])(stream, buf, len);
			#else
			return (int)((delegate* unmanaged[Cdecl]<nint, nint, int, int>)funcTable[345])((nint)stream, (nint)buf, len);
			#endif
		}

		/// <summary>
		/// Get converted/resampled data from the stream.<br/>
		/// The input/output data format/channels/samplerate is specified when creating<br/>
		/// the stream, and can be changed after creation by calling<br/>
		/// SDL_SetAudioStreamFormat.<br/>
		/// Note that any conversion and resampling necessary is done during this call,<br/>
		/// and SDL_PutAudioStreamData simply queues unconverted data for later. This<br/>
		/// is different than SDL2, where that work was done while inputting new data<br/>
		/// to the stream and requesting the output just copied the converted data.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, but if the<br/>
		/// stream has a callback set, the caller might need to manage<br/>
		/// extra locking.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int GetAudioStreamData(SDLAudioStream* stream, void* buf, int len)
		{
			int ret = GetAudioStreamDataNative(stream, buf, len);
			return ret;
		}

		/// <summary>
		/// Get converted/resampled data from the stream.<br/>
		/// The input/output data format/channels/samplerate is specified when creating<br/>
		/// the stream, and can be changed after creation by calling<br/>
		/// SDL_SetAudioStreamFormat.<br/>
		/// Note that any conversion and resampling necessary is done during this call,<br/>
		/// and SDL_PutAudioStreamData simply queues unconverted data for later. This<br/>
		/// is different than SDL2, where that work was done while inputting new data<br/>
		/// to the stream and requesting the output just copied the converted data.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread, but if the<br/>
		/// stream has a callback set, the caller might need to manage<br/>
		/// extra locking.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int GetAudioStreamData(ref SDLAudioStream stream, void* buf, int len)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				int ret = GetAudioStreamDataNative((SDLAudioStream*)pstream, buf, len);
				return ret;
			}
		}

		/// <summary>
		/// Get the number of converted/resampled bytes available.<br/>
		/// The stream may be buffering data behind the scenes until it has enough to<br/>
		/// resample correctly, so this number might be lower than what you expect, or<br/>
		/// even be zero. Add more data or flush the stream if you need the data now.<br/>
		/// If the stream has so much data that it would overflow an int, the return<br/>
		/// value is clamped to a maximum value, but no queued data is lost; if there<br/>
		/// are gigabytes of data queued, the app might need to read some of it with<br/>
		/// SDL_GetAudioStreamData before this function's return value is no longer<br/>
		/// clamped.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static int GetAudioStreamAvailableNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, int>)funcTable[346])(stream);
			#else
			return (int)((delegate* unmanaged[Cdecl]<nint, int>)funcTable[346])((nint)stream);
			#endif
		}

		/// <summary>
		/// Get the number of converted/resampled bytes available.<br/>
		/// The stream may be buffering data behind the scenes until it has enough to<br/>
		/// resample correctly, so this number might be lower than what you expect, or<br/>
		/// even be zero. Add more data or flush the stream if you need the data now.<br/>
		/// If the stream has so much data that it would overflow an int, the return<br/>
		/// value is clamped to a maximum value, but no queued data is lost; if there<br/>
		/// are gigabytes of data queued, the app might need to read some of it with<br/>
		/// SDL_GetAudioStreamData before this function's return value is no longer<br/>
		/// clamped.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int GetAudioStreamAvailable(SDLAudioStream* stream)
		{
			int ret = GetAudioStreamAvailableNative(stream);
			return ret;
		}

		/// <summary>
		/// Get the number of converted/resampled bytes available.<br/>
		/// The stream may be buffering data behind the scenes until it has enough to<br/>
		/// resample correctly, so this number might be lower than what you expect, or<br/>
		/// even be zero. Add more data or flush the stream if you need the data now.<br/>
		/// If the stream has so much data that it would overflow an int, the return<br/>
		/// value is clamped to a maximum value, but no queued data is lost; if there<br/>
		/// are gigabytes of data queued, the app might need to read some of it with<br/>
		/// SDL_GetAudioStreamData before this function's return value is no longer<br/>
		/// clamped.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int GetAudioStreamAvailable(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				int ret = GetAudioStreamAvailableNative((SDLAudioStream*)pstream);
				return ret;
			}
		}

		/// <summary>
		/// Get the number of bytes currently queued.<br/>
		/// This is the number of bytes put into a stream as input, not the number that<br/>
		/// can be retrieved as output. Because of several details, it's not possible<br/>
		/// to calculate one number directly from the other. If you need to know how<br/>
		/// much usable data can be retrieved right now, you should use<br/>
		/// SDL_GetAudioStreamAvailable() and not this function.<br/>
		/// Note that audio streams can change their input format at any time, even if<br/>
		/// there is still data queued in a different format, so the returned byte<br/>
		/// count will not necessarily match the number of _sample frames_ available.<br/>
		/// Users of this API should be aware of format changes they make when feeding<br/>
		/// a stream and plan accordingly.<br/>
		/// Queued data is not converted until it is consumed by<br/>
		/// SDL_GetAudioStreamData, so this value should be representative of the exact<br/>
		/// data that was put into the stream.<br/>
		/// If the stream has so much data that it would overflow an int, the return<br/>
		/// value is clamped to a maximum value, but no queued data is lost; if there<br/>
		/// are gigabytes of data queued, the app might need to read some of it with<br/>
		/// SDL_GetAudioStreamData before this function's return value is no longer<br/>
		/// clamped.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static int GetAudioStreamQueuedNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, int>)funcTable[347])(stream);
			#else
			return (int)((delegate* unmanaged[Cdecl]<nint, int>)funcTable[347])((nint)stream);
			#endif
		}

		/// <summary>
		/// Get the number of bytes currently queued.<br/>
		/// This is the number of bytes put into a stream as input, not the number that<br/>
		/// can be retrieved as output. Because of several details, it's not possible<br/>
		/// to calculate one number directly from the other. If you need to know how<br/>
		/// much usable data can be retrieved right now, you should use<br/>
		/// SDL_GetAudioStreamAvailable() and not this function.<br/>
		/// Note that audio streams can change their input format at any time, even if<br/>
		/// there is still data queued in a different format, so the returned byte<br/>
		/// count will not necessarily match the number of _sample frames_ available.<br/>
		/// Users of this API should be aware of format changes they make when feeding<br/>
		/// a stream and plan accordingly.<br/>
		/// Queued data is not converted until it is consumed by<br/>
		/// SDL_GetAudioStreamData, so this value should be representative of the exact<br/>
		/// data that was put into the stream.<br/>
		/// If the stream has so much data that it would overflow an int, the return<br/>
		/// value is clamped to a maximum value, but no queued data is lost; if there<br/>
		/// are gigabytes of data queued, the app might need to read some of it with<br/>
		/// SDL_GetAudioStreamData before this function's return value is no longer<br/>
		/// clamped.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int GetAudioStreamQueued(SDLAudioStream* stream)
		{
			int ret = GetAudioStreamQueuedNative(stream);
			return ret;
		}

		/// <summary>
		/// Get the number of bytes currently queued.<br/>
		/// This is the number of bytes put into a stream as input, not the number that<br/>
		/// can be retrieved as output. Because of several details, it's not possible<br/>
		/// to calculate one number directly from the other. If you need to know how<br/>
		/// much usable data can be retrieved right now, you should use<br/>
		/// SDL_GetAudioStreamAvailable() and not this function.<br/>
		/// Note that audio streams can change their input format at any time, even if<br/>
		/// there is still data queued in a different format, so the returned byte<br/>
		/// count will not necessarily match the number of _sample frames_ available.<br/>
		/// Users of this API should be aware of format changes they make when feeding<br/>
		/// a stream and plan accordingly.<br/>
		/// Queued data is not converted until it is consumed by<br/>
		/// SDL_GetAudioStreamData, so this value should be representative of the exact<br/>
		/// data that was put into the stream.<br/>
		/// If the stream has so much data that it would overflow an int, the return<br/>
		/// value is clamped to a maximum value, but no queued data is lost; if there<br/>
		/// are gigabytes of data queued, the app might need to read some of it with<br/>
		/// SDL_GetAudioStreamData before this function's return value is no longer<br/>
		/// clamped.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static int GetAudioStreamQueued(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				int ret = GetAudioStreamQueuedNative((SDLAudioStream*)pstream);
				return ret;
			}
		}

		/// <summary>
		/// Tell the stream that you're done sending data, and anything being buffered<br/>
		/// should be converted/resampled and made available immediately.<br/>
		/// It is legal to add more data to a stream after flushing, but there may be<br/>
		/// audio gaps in the output. Generally this is intended to signal the end of<br/>
		/// input, so the complete output becomes available.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte FlushAudioStreamNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, byte>)funcTable[348])(stream);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)funcTable[348])((nint)stream);
			#endif
		}

		/// <summary>
		/// Tell the stream that you're done sending data, and anything being buffered<br/>
		/// should be converted/resampled and made available immediately.<br/>
		/// It is legal to add more data to a stream after flushing, but there may be<br/>
		/// audio gaps in the output. Generally this is intended to signal the end of<br/>
		/// input, so the complete output becomes available.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool FlushAudioStream(SDLAudioStream* stream)
		{
			byte ret = FlushAudioStreamNative(stream);
			return ret != 0;
		}

		/// <summary>
		/// Tell the stream that you're done sending data, and anything being buffered<br/>
		/// should be converted/resampled and made available immediately.<br/>
		/// It is legal to add more data to a stream after flushing, but there may be<br/>
		/// audio gaps in the output. Generally this is intended to signal the end of<br/>
		/// input, so the complete output becomes available.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool FlushAudioStream(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = FlushAudioStreamNative((SDLAudioStream*)pstream);
				return ret != 0;
			}
		}

		/// <summary>
		/// Clear any pending data in the stream.<br/>
		/// This drops any queued data, so there will be nothing to read from the<br/>
		/// stream until more is added.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ClearAudioStreamNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, byte>)funcTable[349])(stream);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)funcTable[349])((nint)stream);
			#endif
		}

		/// <summary>
		/// Clear any pending data in the stream.<br/>
		/// This drops any queued data, so there will be nothing to read from the<br/>
		/// stream until more is added.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool ClearAudioStream(SDLAudioStream* stream)
		{
			byte ret = ClearAudioStreamNative(stream);
			return ret != 0;
		}

		/// <summary>
		/// Clear any pending data in the stream.<br/>
		/// This drops any queued data, so there will be nothing to read from the<br/>
		/// stream until more is added.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool ClearAudioStream(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = ClearAudioStreamNative((SDLAudioStream*)pstream);
				return ret != 0;
			}
		}

		/// <summary>
		/// Use this function to pause audio playback on the audio device associated<br/>
		/// with an audio stream.<br/>
		/// This function pauses audio processing for a given device. Any bound audio<br/>
		/// streams will not progress, and no audio will be generated. Pausing one<br/>
		/// device does not prevent other unpaused devices from running.<br/>
		/// Pausing a device can be useful to halt all audio without unbinding all the<br/>
		/// audio streams. This might be useful while a game is paused, or a level is<br/>
		/// loading, etc.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte PauseAudioStreamDeviceNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, byte>)funcTable[350])(stream);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)funcTable[350])((nint)stream);
			#endif
		}

		/// <summary>
		/// Use this function to pause audio playback on the audio device associated<br/>
		/// with an audio stream.<br/>
		/// This function pauses audio processing for a given device. Any bound audio<br/>
		/// streams will not progress, and no audio will be generated. Pausing one<br/>
		/// device does not prevent other unpaused devices from running.<br/>
		/// Pausing a device can be useful to halt all audio without unbinding all the<br/>
		/// audio streams. This might be useful while a game is paused, or a level is<br/>
		/// loading, etc.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool PauseAudioStreamDevice(SDLAudioStream* stream)
		{
			byte ret = PauseAudioStreamDeviceNative(stream);
			return ret != 0;
		}

		/// <summary>
		/// Use this function to pause audio playback on the audio device associated<br/>
		/// with an audio stream.<br/>
		/// This function pauses audio processing for a given device. Any bound audio<br/>
		/// streams will not progress, and no audio will be generated. Pausing one<br/>
		/// device does not prevent other unpaused devices from running.<br/>
		/// Pausing a device can be useful to halt all audio without unbinding all the<br/>
		/// audio streams. This might be useful while a game is paused, or a level is<br/>
		/// loading, etc.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool PauseAudioStreamDevice(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = PauseAudioStreamDeviceNative((SDLAudioStream*)pstream);
				return ret != 0;
			}
		}

		/// <summary>
		/// Use this function to unpause audio playback on the audio device associated<br/>
		/// with an audio stream.<br/>
		/// This function unpauses audio processing for a given device that has<br/>
		/// previously been paused. Once unpaused, any bound audio streams will begin<br/>
		/// to progress again, and audio can be generated.<br/>
		/// Remember, SDL_OpenAudioDeviceStream opens device in a paused state, so this<br/>
		/// function call is required for audio playback to begin on such device.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ResumeAudioStreamDeviceNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, byte>)funcTable[351])(stream);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)funcTable[351])((nint)stream);
			#endif
		}

		/// <summary>
		/// Use this function to unpause audio playback on the audio device associated<br/>
		/// with an audio stream.<br/>
		/// This function unpauses audio processing for a given device that has<br/>
		/// previously been paused. Once unpaused, any bound audio streams will begin<br/>
		/// to progress again, and audio can be generated.<br/>
		/// Remember, SDL_OpenAudioDeviceStream opens device in a paused state, so this<br/>
		/// function call is required for audio playback to begin on such device.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool ResumeAudioStreamDevice(SDLAudioStream* stream)
		{
			byte ret = ResumeAudioStreamDeviceNative(stream);
			return ret != 0;
		}

		/// <summary>
		/// Use this function to unpause audio playback on the audio device associated<br/>
		/// with an audio stream.<br/>
		/// This function unpauses audio processing for a given device that has<br/>
		/// previously been paused. Once unpaused, any bound audio streams will begin<br/>
		/// to progress again, and audio can be generated.<br/>
		/// Remember, SDL_OpenAudioDeviceStream opens device in a paused state, so this<br/>
		/// function call is required for audio playback to begin on such device.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool ResumeAudioStreamDevice(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = ResumeAudioStreamDeviceNative((SDLAudioStream*)pstream);
				return ret != 0;
			}
		}

		/// <summary>
		/// Use this function to query if an audio device associated with a stream is<br/>
		/// paused.<br/>
		/// Unlike in SDL2, audio devices start in an _unpaused_ state, since an app<br/>
		/// has to bind a stream before any audio will flow.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte AudioStreamDevicePausedNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, byte>)funcTable[352])(stream);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)funcTable[352])((nint)stream);
			#endif
		}

		/// <summary>
		/// Use this function to query if an audio device associated with a stream is<br/>
		/// paused.<br/>
		/// Unlike in SDL2, audio devices start in an _unpaused_ state, since an app<br/>
		/// has to bind a stream before any audio will flow.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool AudioStreamDevicePaused(SDLAudioStream* stream)
		{
			byte ret = AudioStreamDevicePausedNative(stream);
			return ret != 0;
		}

		/// <summary>
		/// Use this function to query if an audio device associated with a stream is<br/>
		/// paused.<br/>
		/// Unlike in SDL2, audio devices start in an _unpaused_ state, since an app<br/>
		/// has to bind a stream before any audio will flow.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool AudioStreamDevicePaused(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = AudioStreamDevicePausedNative((SDLAudioStream*)pstream);
				return ret != 0;
			}
		}

		/// <summary>
		/// Lock an audio stream for serialized access.<br/>
		/// Each SDL_AudioStream has an internal mutex it uses to protect its data<br/>
		/// structures from threading conflicts. This function allows an app to lock<br/>
		/// that mutex, which could be useful if registering callbacks on this stream.<br/>
		/// One does not need to lock a stream to use in it most cases, as the stream<br/>
		/// manages this lock internally. However, this lock is held during callbacks,<br/>
		/// which may run from arbitrary threads at any time, so if an app needs to<br/>
		/// protect shared data during those callbacks, locking the stream guarantees<br/>
		/// that the callback is not running while the lock is held.<br/>
		/// As this is just a wrapper over SDL_LockMutex for an internal lock; it has<br/>
		/// all the same attributes (recursive locks are allowed, etc).<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte LockAudioStreamNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, byte>)funcTable[353])(stream);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)funcTable[353])((nint)stream);
			#endif
		}

		/// <summary>
		/// Lock an audio stream for serialized access.<br/>
		/// Each SDL_AudioStream has an internal mutex it uses to protect its data<br/>
		/// structures from threading conflicts. This function allows an app to lock<br/>
		/// that mutex, which could be useful if registering callbacks on this stream.<br/>
		/// One does not need to lock a stream to use in it most cases, as the stream<br/>
		/// manages this lock internally. However, this lock is held during callbacks,<br/>
		/// which may run from arbitrary threads at any time, so if an app needs to<br/>
		/// protect shared data during those callbacks, locking the stream guarantees<br/>
		/// that the callback is not running while the lock is held.<br/>
		/// As this is just a wrapper over SDL_LockMutex for an internal lock; it has<br/>
		/// all the same attributes (recursive locks are allowed, etc).<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LockAudioStream(SDLAudioStream* stream)
		{
			byte ret = LockAudioStreamNative(stream);
			return ret != 0;
		}

		/// <summary>
		/// Lock an audio stream for serialized access.<br/>
		/// Each SDL_AudioStream has an internal mutex it uses to protect its data<br/>
		/// structures from threading conflicts. This function allows an app to lock<br/>
		/// that mutex, which could be useful if registering callbacks on this stream.<br/>
		/// One does not need to lock a stream to use in it most cases, as the stream<br/>
		/// manages this lock internally. However, this lock is held during callbacks,<br/>
		/// which may run from arbitrary threads at any time, so if an app needs to<br/>
		/// protect shared data during those callbacks, locking the stream guarantees<br/>
		/// that the callback is not running while the lock is held.<br/>
		/// As this is just a wrapper over SDL_LockMutex for an internal lock; it has<br/>
		/// all the same attributes (recursive locks are allowed, etc).<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LockAudioStream(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = LockAudioStreamNative((SDLAudioStream*)pstream);
				return ret != 0;
			}
		}

		/// <summary>
		/// Unlock an audio stream for serialized access.<br/>
		/// This unlocks an audio stream after a call to SDL_LockAudioStream.<br/>
		/// <br/>
		/// <br/>
		/// You should only call this from the same thread that<br/>
		/// previously called SDL_LockAudioStream.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte UnlockAudioStreamNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, byte>)funcTable[354])(stream);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)funcTable[354])((nint)stream);
			#endif
		}

		/// <summary>
		/// Unlock an audio stream for serialized access.<br/>
		/// This unlocks an audio stream after a call to SDL_LockAudioStream.<br/>
		/// <br/>
		/// <br/>
		/// You should only call this from the same thread that<br/>
		/// previously called SDL_LockAudioStream.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool UnlockAudioStream(SDLAudioStream* stream)
		{
			byte ret = UnlockAudioStreamNative(stream);
			return ret != 0;
		}

		/// <summary>
		/// Unlock an audio stream for serialized access.<br/>
		/// This unlocks an audio stream after a call to SDL_LockAudioStream.<br/>
		/// <br/>
		/// <br/>
		/// You should only call this from the same thread that<br/>
		/// previously called SDL_LockAudioStream.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool UnlockAudioStream(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = UnlockAudioStreamNative((SDLAudioStream*)pstream);
				return ret != 0;
			}
		}

		/// <summary>
		/// Set a callback that runs when data is requested from an audio stream.<br/>
		/// This callback is called _before_ data is obtained from the stream, giving<br/>
		/// the callback the chance to add more on-demand.<br/>
		/// The callback can (optionally) call SDL_PutAudioStreamData() to add more<br/>
		/// audio to the stream during this call; if needed, the request that triggered<br/>
		/// this callback will obtain the new data immediately.<br/>
		/// The callback's `additional_amount` argument is roughly how many bytes of<br/>
		/// _unconverted_ data (in the stream's input format) is needed by the caller,<br/>
		/// although this may overestimate a little for safety. This takes into account<br/>
		/// how much is already in the stream and only asks for any extra necessary to<br/>
		/// resolve the request, which means the callback may be asked for zero bytes,<br/>
		/// and a different amount on each call.<br/>
		/// The callback is not required to supply exact amounts; it is allowed to<br/>
		/// supply too much or too little or none at all. The caller will get what's<br/>
		/// available, up to the amount they requested, regardless of this callback's<br/>
		/// outcome.<br/>
		/// Clearing or flushing an audio stream does not call this callback.<br/>
		/// This function obtains the stream's lock, which means any existing callback<br/>
		/// (get or put) in progress will finish running before setting the new<br/>
		/// callback.<br/>
		/// Setting a NULL function turns off the callback.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte SetAudioStreamGetCallbackNative(SDLAudioStream* stream, SDLAudioStreamCallback callback, void* userdata)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, delegate*<void*, SDLAudioStream*, int, int, void>, void*, byte>)funcTable[355])(stream, (delegate*<void*, SDLAudioStream*, int, int, void>)Utils.GetFunctionPointerForDelegate(callback), userdata);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, nint, nint, byte>)funcTable[355])((nint)stream, (nint)Utils.GetFunctionPointerForDelegate(callback), (nint)userdata);
			#endif
		}

		/// <summary>
		/// Set a callback that runs when data is requested from an audio stream.<br/>
		/// This callback is called _before_ data is obtained from the stream, giving<br/>
		/// the callback the chance to add more on-demand.<br/>
		/// The callback can (optionally) call SDL_PutAudioStreamData() to add more<br/>
		/// audio to the stream during this call; if needed, the request that triggered<br/>
		/// this callback will obtain the new data immediately.<br/>
		/// The callback's `additional_amount` argument is roughly how many bytes of<br/>
		/// _unconverted_ data (in the stream's input format) is needed by the caller,<br/>
		/// although this may overestimate a little for safety. This takes into account<br/>
		/// how much is already in the stream and only asks for any extra necessary to<br/>
		/// resolve the request, which means the callback may be asked for zero bytes,<br/>
		/// and a different amount on each call.<br/>
		/// The callback is not required to supply exact amounts; it is allowed to<br/>
		/// supply too much or too little or none at all. The caller will get what's<br/>
		/// available, up to the amount they requested, regardless of this callback's<br/>
		/// outcome.<br/>
		/// Clearing or flushing an audio stream does not call this callback.<br/>
		/// This function obtains the stream's lock, which means any existing callback<br/>
		/// (get or put) in progress will finish running before setting the new<br/>
		/// callback.<br/>
		/// Setting a NULL function turns off the callback.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamGetCallback(SDLAudioStream* stream, SDLAudioStreamCallback callback, void* userdata)
		{
			byte ret = SetAudioStreamGetCallbackNative(stream, callback, userdata);
			return ret != 0;
		}

		/// <summary>
		/// Set a callback that runs when data is requested from an audio stream.<br/>
		/// This callback is called _before_ data is obtained from the stream, giving<br/>
		/// the callback the chance to add more on-demand.<br/>
		/// The callback can (optionally) call SDL_PutAudioStreamData() to add more<br/>
		/// audio to the stream during this call; if needed, the request that triggered<br/>
		/// this callback will obtain the new data immediately.<br/>
		/// The callback's `additional_amount` argument is roughly how many bytes of<br/>
		/// _unconverted_ data (in the stream's input format) is needed by the caller,<br/>
		/// although this may overestimate a little for safety. This takes into account<br/>
		/// how much is already in the stream and only asks for any extra necessary to<br/>
		/// resolve the request, which means the callback may be asked for zero bytes,<br/>
		/// and a different amount on each call.<br/>
		/// The callback is not required to supply exact amounts; it is allowed to<br/>
		/// supply too much or too little or none at all. The caller will get what's<br/>
		/// available, up to the amount they requested, regardless of this callback's<br/>
		/// outcome.<br/>
		/// Clearing or flushing an audio stream does not call this callback.<br/>
		/// This function obtains the stream's lock, which means any existing callback<br/>
		/// (get or put) in progress will finish running before setting the new<br/>
		/// callback.<br/>
		/// Setting a NULL function turns off the callback.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamGetCallback(ref SDLAudioStream stream, SDLAudioStreamCallback callback, void* userdata)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = SetAudioStreamGetCallbackNative((SDLAudioStream*)pstream, callback, userdata);
				return ret != 0;
			}
		}

		/// <summary>
		/// Set a callback that runs when data is added to an audio stream.<br/>
		/// This callback is called _after_ the data is added to the stream, giving the<br/>
		/// callback the chance to obtain it immediately.<br/>
		/// The callback can (optionally) call SDL_GetAudioStreamData() to obtain audio<br/>
		/// from the stream during this call.<br/>
		/// The callback's `additional_amount` argument is how many bytes of<br/>
		/// _converted_ data (in the stream's output format) was provided by the<br/>
		/// caller, although this may underestimate a little for safety. This value<br/>
		/// might be less than what is currently available in the stream, if data was<br/>
		/// already there, and might be less than the caller provided if the stream<br/>
		/// needs to keep a buffer to aid in resampling. Which means the callback may<br/>
		/// be provided with zero bytes, and a different amount on each call.<br/>
		/// The callback may call SDL_GetAudioStreamAvailable to see the total amount<br/>
		/// currently available to read from the stream, instead of the total provided<br/>
		/// by the current call.<br/>
		/// The callback is not required to obtain all data. It is allowed to read less<br/>
		/// or none at all. Anything not read now simply remains in the stream for<br/>
		/// later access.<br/>
		/// Clearing or flushing an audio stream does not call this callback.<br/>
		/// This function obtains the stream's lock, which means any existing callback<br/>
		/// (get or put) in progress will finish running before setting the new<br/>
		/// callback.<br/>
		/// Setting a NULL function turns off the callback.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte SetAudioStreamPutCallbackNative(SDLAudioStream* stream, SDLAudioStreamCallback callback, void* userdata)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLAudioStream*, delegate*<void*, SDLAudioStream*, int, int, void>, void*, byte>)funcTable[356])(stream, (delegate*<void*, SDLAudioStream*, int, int, void>)Utils.GetFunctionPointerForDelegate(callback), userdata);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, nint, nint, byte>)funcTable[356])((nint)stream, (nint)Utils.GetFunctionPointerForDelegate(callback), (nint)userdata);
			#endif
		}

		/// <summary>
		/// Set a callback that runs when data is added to an audio stream.<br/>
		/// This callback is called _after_ the data is added to the stream, giving the<br/>
		/// callback the chance to obtain it immediately.<br/>
		/// The callback can (optionally) call SDL_GetAudioStreamData() to obtain audio<br/>
		/// from the stream during this call.<br/>
		/// The callback's `additional_amount` argument is how many bytes of<br/>
		/// _converted_ data (in the stream's output format) was provided by the<br/>
		/// caller, although this may underestimate a little for safety. This value<br/>
		/// might be less than what is currently available in the stream, if data was<br/>
		/// already there, and might be less than the caller provided if the stream<br/>
		/// needs to keep a buffer to aid in resampling. Which means the callback may<br/>
		/// be provided with zero bytes, and a different amount on each call.<br/>
		/// The callback may call SDL_GetAudioStreamAvailable to see the total amount<br/>
		/// currently available to read from the stream, instead of the total provided<br/>
		/// by the current call.<br/>
		/// The callback is not required to obtain all data. It is allowed to read less<br/>
		/// or none at all. Anything not read now simply remains in the stream for<br/>
		/// later access.<br/>
		/// Clearing or flushing an audio stream does not call this callback.<br/>
		/// This function obtains the stream's lock, which means any existing callback<br/>
		/// (get or put) in progress will finish running before setting the new<br/>
		/// callback.<br/>
		/// Setting a NULL function turns off the callback.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamPutCallback(SDLAudioStream* stream, SDLAudioStreamCallback callback, void* userdata)
		{
			byte ret = SetAudioStreamPutCallbackNative(stream, callback, userdata);
			return ret != 0;
		}

		/// <summary>
		/// Set a callback that runs when data is added to an audio stream.<br/>
		/// This callback is called _after_ the data is added to the stream, giving the<br/>
		/// callback the chance to obtain it immediately.<br/>
		/// The callback can (optionally) call SDL_GetAudioStreamData() to obtain audio<br/>
		/// from the stream during this call.<br/>
		/// The callback's `additional_amount` argument is how many bytes of<br/>
		/// _converted_ data (in the stream's output format) was provided by the<br/>
		/// caller, although this may underestimate a little for safety. This value<br/>
		/// might be less than what is currently available in the stream, if data was<br/>
		/// already there, and might be less than the caller provided if the stream<br/>
		/// needs to keep a buffer to aid in resampling. Which means the callback may<br/>
		/// be provided with zero bytes, and a different amount on each call.<br/>
		/// The callback may call SDL_GetAudioStreamAvailable to see the total amount<br/>
		/// currently available to read from the stream, instead of the total provided<br/>
		/// by the current call.<br/>
		/// The callback is not required to obtain all data. It is allowed to read less<br/>
		/// or none at all. Anything not read now simply remains in the stream for<br/>
		/// later access.<br/>
		/// Clearing or flushing an audio stream does not call this callback.<br/>
		/// This function obtains the stream's lock, which means any existing callback<br/>
		/// (get or put) in progress will finish running before setting the new<br/>
		/// callback.<br/>
		/// Setting a NULL function turns off the callback.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioStreamPutCallback(ref SDLAudioStream stream, SDLAudioStreamCallback callback, void* userdata)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				byte ret = SetAudioStreamPutCallbackNative((SDLAudioStream*)pstream, callback, userdata);
				return ret != 0;
			}
		}

		/// <summary>
		/// Free an audio stream.<br/>
		/// This will release all allocated data, including any audio that is still<br/>
		/// queued. You do not need to manually clear the stream first.<br/>
		/// If this stream was bound to an audio device, it is unbound during this<br/>
		/// call. If this stream was created with SDL_OpenAudioDeviceStream, the audio<br/>
		/// device that was opened alongside this stream's creation will be closed,<br/>
		/// too.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void DestroyAudioStreamNative(SDLAudioStream* stream)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<SDLAudioStream*, void>)funcTable[357])(stream);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)funcTable[357])((nint)stream);
			#endif
		}

		/// <summary>
		/// Free an audio stream.<br/>
		/// This will release all allocated data, including any audio that is still<br/>
		/// queued. You do not need to manually clear the stream first.<br/>
		/// If this stream was bound to an audio device, it is unbound during this<br/>
		/// call. If this stream was created with SDL_OpenAudioDeviceStream, the audio<br/>
		/// device that was opened alongside this stream's creation will be closed,<br/>
		/// too.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static void DestroyAudioStream(SDLAudioStream* stream)
		{
			DestroyAudioStreamNative(stream);
		}

		/// <summary>
		/// Free an audio stream.<br/>
		/// This will release all allocated data, including any audio that is still<br/>
		/// queued. You do not need to manually clear the stream first.<br/>
		/// If this stream was bound to an audio device, it is unbound during this<br/>
		/// call. If this stream was created with SDL_OpenAudioDeviceStream, the audio<br/>
		/// device that was opened alongside this stream's creation will be closed,<br/>
		/// too.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static void DestroyAudioStream(ref SDLAudioStream stream)
		{
			fixed (SDLAudioStream* pstream = &stream)
			{
				DestroyAudioStreamNative((SDLAudioStream*)pstream);
			}
		}

		/// <summary>
		/// Convenience function for straightforward audio init for the common case.<br/>
		/// If all your app intends to do is provide a single source of PCM audio, this<br/>
		/// function allows you to do all your audio setup in a single call.<br/>
		/// This is also intended to be a clean means to migrate apps from SDL2.<br/>
		/// This function will open an audio device, create a stream and bind it.<br/>
		/// Unlike other methods of setup, the audio device will be closed when this<br/>
		/// stream is destroyed, so the app can treat the returned SDL_AudioStream as<br/>
		/// the only object needed to manage audio playback.<br/>
		/// Also unlike other functions, the audio device begins paused. This is to map<br/>
		/// more closely to SDL2-style behavior, since there is no extra step here to<br/>
		/// bind a stream to begin audio flowing. The audio device should be resumed<br/>
		/// with `SDL_ResumeAudioStreamDevice(stream);`<br/>
		/// This function works with both playback and recording devices.<br/>
		/// The `spec` parameter represents the app's side of the audio stream. That<br/>
		/// is, for recording audio, this will be the output format, and for playing<br/>
		/// audio, this will be the input format. If spec is NULL, the system will<br/>
		/// choose the format, and the app can use SDL_GetAudioStreamFormat() to obtain<br/>
		/// this information later.<br/>
		/// If you don't care about opening a specific audio device, you can (and<br/>
		/// probably _should_), use SDL_AUDIO_DEVICE_DEFAULT_PLAYBACK for playback and<br/>
		/// SDL_AUDIO_DEVICE_DEFAULT_RECORDING for recording.<br/>
		/// One can optionally provide a callback function; if NULL, the app is<br/>
		/// expected to queue audio data for playback (or unqueue audio data if<br/>
		/// capturing). Otherwise, the callback will begin to fire once the device is<br/>
		/// unpaused.<br/>
		/// Destroying the returned stream with SDL_DestroyAudioStream will also close<br/>
		/// the audio device associated with this stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static SDLAudioStream* OpenAudioDeviceStreamNative(uint devid, SDLAudioSpec* spec, SDLAudioStreamCallback callback, void* userdata)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, SDLAudioSpec*, delegate*<void*, SDLAudioStream*, int, int, void>, void*, SDLAudioStream*>)funcTable[358])(devid, spec, (delegate*<void*, SDLAudioStream*, int, int, void>)Utils.GetFunctionPointerForDelegate(callback), userdata);
			#else
			return (SDLAudioStream*)((delegate* unmanaged[Cdecl]<uint, nint, nint, nint, nint>)funcTable[358])(devid, (nint)spec, (nint)Utils.GetFunctionPointerForDelegate(callback), (nint)userdata);
			#endif
		}

		/// <summary>
		/// Convenience function for straightforward audio init for the common case.<br/>
		/// If all your app intends to do is provide a single source of PCM audio, this<br/>
		/// function allows you to do all your audio setup in a single call.<br/>
		/// This is also intended to be a clean means to migrate apps from SDL2.<br/>
		/// This function will open an audio device, create a stream and bind it.<br/>
		/// Unlike other methods of setup, the audio device will be closed when this<br/>
		/// stream is destroyed, so the app can treat the returned SDL_AudioStream as<br/>
		/// the only object needed to manage audio playback.<br/>
		/// Also unlike other functions, the audio device begins paused. This is to map<br/>
		/// more closely to SDL2-style behavior, since there is no extra step here to<br/>
		/// bind a stream to begin audio flowing. The audio device should be resumed<br/>
		/// with `SDL_ResumeAudioStreamDevice(stream);`<br/>
		/// This function works with both playback and recording devices.<br/>
		/// The `spec` parameter represents the app's side of the audio stream. That<br/>
		/// is, for recording audio, this will be the output format, and for playing<br/>
		/// audio, this will be the input format. If spec is NULL, the system will<br/>
		/// choose the format, and the app can use SDL_GetAudioStreamFormat() to obtain<br/>
		/// this information later.<br/>
		/// If you don't care about opening a specific audio device, you can (and<br/>
		/// probably _should_), use SDL_AUDIO_DEVICE_DEFAULT_PLAYBACK for playback and<br/>
		/// SDL_AUDIO_DEVICE_DEFAULT_RECORDING for recording.<br/>
		/// One can optionally provide a callback function; if NULL, the app is<br/>
		/// expected to queue audio data for playback (or unqueue audio data if<br/>
		/// capturing). Otherwise, the callback will begin to fire once the device is<br/>
		/// unpaused.<br/>
		/// Destroying the returned stream with SDL_DestroyAudioStream will also close<br/>
		/// the audio device associated with this stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static SDLAudioStream* OpenAudioDeviceStream(uint devid, SDLAudioSpec* spec, SDLAudioStreamCallback callback, void* userdata)
		{
			SDLAudioStream* ret = OpenAudioDeviceStreamNative(devid, spec, callback, userdata);
			return ret;
		}

		/// <summary>
		/// Convenience function for straightforward audio init for the common case.<br/>
		/// If all your app intends to do is provide a single source of PCM audio, this<br/>
		/// function allows you to do all your audio setup in a single call.<br/>
		/// This is also intended to be a clean means to migrate apps from SDL2.<br/>
		/// This function will open an audio device, create a stream and bind it.<br/>
		/// Unlike other methods of setup, the audio device will be closed when this<br/>
		/// stream is destroyed, so the app can treat the returned SDL_AudioStream as<br/>
		/// the only object needed to manage audio playback.<br/>
		/// Also unlike other functions, the audio device begins paused. This is to map<br/>
		/// more closely to SDL2-style behavior, since there is no extra step here to<br/>
		/// bind a stream to begin audio flowing. The audio device should be resumed<br/>
		/// with `SDL_ResumeAudioStreamDevice(stream);`<br/>
		/// This function works with both playback and recording devices.<br/>
		/// The `spec` parameter represents the app's side of the audio stream. That<br/>
		/// is, for recording audio, this will be the output format, and for playing<br/>
		/// audio, this will be the input format. If spec is NULL, the system will<br/>
		/// choose the format, and the app can use SDL_GetAudioStreamFormat() to obtain<br/>
		/// this information later.<br/>
		/// If you don't care about opening a specific audio device, you can (and<br/>
		/// probably _should_), use SDL_AUDIO_DEVICE_DEFAULT_PLAYBACK for playback and<br/>
		/// SDL_AUDIO_DEVICE_DEFAULT_RECORDING for recording.<br/>
		/// One can optionally provide a callback function; if NULL, the app is<br/>
		/// expected to queue audio data for playback (or unqueue audio data if<br/>
		/// capturing). Otherwise, the callback will begin to fire once the device is<br/>
		/// unpaused.<br/>
		/// Destroying the returned stream with SDL_DestroyAudioStream will also close<br/>
		/// the audio device associated with this stream.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static SDLAudioStream* OpenAudioDeviceStream(uint devid, ref SDLAudioSpec spec, SDLAudioStreamCallback callback, void* userdata)
		{
			fixed (SDLAudioSpec* pspec = &spec)
			{
				SDLAudioStream* ret = OpenAudioDeviceStreamNative(devid, (SDLAudioSpec*)pspec, callback, userdata);
				return ret;
			}
		}

		/// <summary>
		/// Set a callback that fires when data is about to be fed to an audio device.<br/>
		/// This is useful for accessing the final mix, perhaps for writing a<br/>
		/// visualizer or applying a final effect to the audio data before playback.<br/>
		/// The buffer is the final mix of all bound audio streams on an opened device;<br/>
		/// this callback will fire regularly for any device that is both opened and<br/>
		/// unpaused. If there is no new data to mix, either because no streams are<br/>
		/// bound to the device or all the streams are empty, this callback will still<br/>
		/// fire with the entire buffer set to silence.<br/>
		/// This callback is allowed to make changes to the data; the contents of the<br/>
		/// buffer after this call is what is ultimately passed along to the hardware.<br/>
		/// The callback is always provided the data in float format (values from -1.0f<br/>
		/// to 1.0f), but the number of channels or sample rate may be different than<br/>
		/// the format the app requested when opening the device; SDL might have had to<br/>
		/// manage a conversion behind the scenes, or the playback might have jumped to<br/>
		/// new physical hardware when a system default changed, etc. These details may<br/>
		/// change between calls. Accordingly, the size of the buffer might change<br/>
		/// between calls as well.<br/>
		/// This callback can run at any time, and from any thread; if you need to<br/>
		/// serialize access to your app's data, you should provide and use a mutex or<br/>
		/// other synchronization device.<br/>
		/// All of this to say: there are specific needs this callback can fulfill, but<br/>
		/// it is not the simplest interface. Apps should generally provide audio in<br/>
		/// their preferred format through an SDL_AudioStream and let SDL handle the<br/>
		/// difference.<br/>
		/// This function is extremely time-sensitive; the callback should do the least<br/>
		/// amount of work possible and return as quickly as it can. The longer the<br/>
		/// callback runs, the higher the risk of audio dropouts or other problems.<br/>
		/// This function will block until the audio device is in between iterations,<br/>
		/// so any existing callback that might be running will finish before this<br/>
		/// function sets the new callback and returns.<br/>
		/// Setting a NULL callback function disables any previously-set callback.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte SetAudioPostmixCallbackNative(uint devid, SDLAudioPostmixCallback callback, void* userdata)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, delegate*<void*, SDLAudioSpec*, float*, int, void>, void*, byte>)funcTable[359])(devid, (delegate*<void*, SDLAudioSpec*, float*, int, void>)Utils.GetFunctionPointerForDelegate(callback), userdata);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<uint, nint, nint, byte>)funcTable[359])(devid, (nint)Utils.GetFunctionPointerForDelegate(callback), (nint)userdata);
			#endif
		}

		/// <summary>
		/// Set a callback that fires when data is about to be fed to an audio device.<br/>
		/// This is useful for accessing the final mix, perhaps for writing a<br/>
		/// visualizer or applying a final effect to the audio data before playback.<br/>
		/// The buffer is the final mix of all bound audio streams on an opened device;<br/>
		/// this callback will fire regularly for any device that is both opened and<br/>
		/// unpaused. If there is no new data to mix, either because no streams are<br/>
		/// bound to the device or all the streams are empty, this callback will still<br/>
		/// fire with the entire buffer set to silence.<br/>
		/// This callback is allowed to make changes to the data; the contents of the<br/>
		/// buffer after this call is what is ultimately passed along to the hardware.<br/>
		/// The callback is always provided the data in float format (values from -1.0f<br/>
		/// to 1.0f), but the number of channels or sample rate may be different than<br/>
		/// the format the app requested when opening the device; SDL might have had to<br/>
		/// manage a conversion behind the scenes, or the playback might have jumped to<br/>
		/// new physical hardware when a system default changed, etc. These details may<br/>
		/// change between calls. Accordingly, the size of the buffer might change<br/>
		/// between calls as well.<br/>
		/// This callback can run at any time, and from any thread; if you need to<br/>
		/// serialize access to your app's data, you should provide and use a mutex or<br/>
		/// other synchronization device.<br/>
		/// All of this to say: there are specific needs this callback can fulfill, but<br/>
		/// it is not the simplest interface. Apps should generally provide audio in<br/>
		/// their preferred format through an SDL_AudioStream and let SDL handle the<br/>
		/// difference.<br/>
		/// This function is extremely time-sensitive; the callback should do the least<br/>
		/// amount of work possible and return as quickly as it can. The longer the<br/>
		/// callback runs, the higher the risk of audio dropouts or other problems.<br/>
		/// This function will block until the audio device is in between iterations,<br/>
		/// so any existing callback that might be running will finish before this<br/>
		/// function sets the new callback and returns.<br/>
		/// Setting a NULL callback function disables any previously-set callback.<br/>
		/// <br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// </summary>
		public static bool SetAudioPostmixCallback(uint devid, SDLAudioPostmixCallback callback, void* userdata)
		{
			byte ret = SetAudioPostmixCallbackNative(devid, callback, userdata);
			return ret != 0;
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte LoadWAVIONative(SDLIOStream* src, byte closeio, SDLAudioSpec* spec, byte** audioBuf, uint* audioLen)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<SDLIOStream*, byte, SDLAudioSpec*, byte**, uint*, byte>)funcTable[360])(src, closeio, spec, audioBuf, audioLen);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte, nint, nint, nint, byte>)funcTable[360])((nint)src, closeio, (nint)spec, (nint)audioBuf, (nint)audioLen);
			#endif
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(SDLIOStream* src, bool closeio, SDLAudioSpec* spec, byte** audioBuf, uint* audioLen)
		{
			byte ret = LoadWAVIONative(src, closeio ? (byte)1 : (byte)0, spec, audioBuf, audioLen);
			return ret != 0;
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(ref SDLIOStream src, bool closeio, SDLAudioSpec* spec, byte** audioBuf, uint* audioLen)
		{
			fixed (SDLIOStream* psrc = &src)
			{
				byte ret = LoadWAVIONative((SDLIOStream*)psrc, closeio ? (byte)1 : (byte)0, spec, audioBuf, audioLen);
				return ret != 0;
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(SDLIOStream* src, bool closeio, ref SDLAudioSpec spec, byte** audioBuf, uint* audioLen)
		{
			fixed (SDLAudioSpec* pspec = &spec)
			{
				byte ret = LoadWAVIONative(src, closeio ? (byte)1 : (byte)0, (SDLAudioSpec*)pspec, audioBuf, audioLen);
				return ret != 0;
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(ref SDLIOStream src, bool closeio, ref SDLAudioSpec spec, byte** audioBuf, uint* audioLen)
		{
			fixed (SDLIOStream* psrc = &src)
			{
				fixed (SDLAudioSpec* pspec = &spec)
				{
					byte ret = LoadWAVIONative((SDLIOStream*)psrc, closeio ? (byte)1 : (byte)0, (SDLAudioSpec*)pspec, audioBuf, audioLen);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(SDLIOStream* src, bool closeio, SDLAudioSpec* spec, ref byte* audioBuf, uint* audioLen)
		{
			fixed (byte** paudioBuf = &audioBuf)
			{
				byte ret = LoadWAVIONative(src, closeio ? (byte)1 : (byte)0, spec, (byte**)paudioBuf, audioLen);
				return ret != 0;
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(ref SDLIOStream src, bool closeio, SDLAudioSpec* spec, ref byte* audioBuf, uint* audioLen)
		{
			fixed (SDLIOStream* psrc = &src)
			{
				fixed (byte** paudioBuf = &audioBuf)
				{
					byte ret = LoadWAVIONative((SDLIOStream*)psrc, closeio ? (byte)1 : (byte)0, spec, (byte**)paudioBuf, audioLen);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(SDLIOStream* src, bool closeio, ref SDLAudioSpec spec, ref byte* audioBuf, uint* audioLen)
		{
			fixed (SDLAudioSpec* pspec = &spec)
			{
				fixed (byte** paudioBuf = &audioBuf)
				{
					byte ret = LoadWAVIONative(src, closeio ? (byte)1 : (byte)0, (SDLAudioSpec*)pspec, (byte**)paudioBuf, audioLen);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(ref SDLIOStream src, bool closeio, ref SDLAudioSpec spec, ref byte* audioBuf, uint* audioLen)
		{
			fixed (SDLIOStream* psrc = &src)
			{
				fixed (SDLAudioSpec* pspec = &spec)
				{
					fixed (byte** paudioBuf = &audioBuf)
					{
						byte ret = LoadWAVIONative((SDLIOStream*)psrc, closeio ? (byte)1 : (byte)0, (SDLAudioSpec*)pspec, (byte**)paudioBuf, audioLen);
						return ret != 0;
					}
				}
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(SDLIOStream* src, bool closeio, SDLAudioSpec* spec, byte** audioBuf, ref uint audioLen)
		{
			fixed (uint* paudioLen = &audioLen)
			{
				byte ret = LoadWAVIONative(src, closeio ? (byte)1 : (byte)0, spec, audioBuf, (uint*)paudioLen);
				return ret != 0;
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(ref SDLIOStream src, bool closeio, SDLAudioSpec* spec, byte** audioBuf, ref uint audioLen)
		{
			fixed (SDLIOStream* psrc = &src)
			{
				fixed (uint* paudioLen = &audioLen)
				{
					byte ret = LoadWAVIONative((SDLIOStream*)psrc, closeio ? (byte)1 : (byte)0, spec, audioBuf, (uint*)paudioLen);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(SDLIOStream* src, bool closeio, ref SDLAudioSpec spec, byte** audioBuf, ref uint audioLen)
		{
			fixed (SDLAudioSpec* pspec = &spec)
			{
				fixed (uint* paudioLen = &audioLen)
				{
					byte ret = LoadWAVIONative(src, closeio ? (byte)1 : (byte)0, (SDLAudioSpec*)pspec, audioBuf, (uint*)paudioLen);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(ref SDLIOStream src, bool closeio, ref SDLAudioSpec spec, byte** audioBuf, ref uint audioLen)
		{
			fixed (SDLIOStream* psrc = &src)
			{
				fixed (SDLAudioSpec* pspec = &spec)
				{
					fixed (uint* paudioLen = &audioLen)
					{
						byte ret = LoadWAVIONative((SDLIOStream*)psrc, closeio ? (byte)1 : (byte)0, (SDLAudioSpec*)pspec, audioBuf, (uint*)paudioLen);
						return ret != 0;
					}
				}
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(SDLIOStream* src, bool closeio, SDLAudioSpec* spec, ref byte* audioBuf, ref uint audioLen)
		{
			fixed (byte** paudioBuf = &audioBuf)
			{
				fixed (uint* paudioLen = &audioLen)
				{
					byte ret = LoadWAVIONative(src, closeio ? (byte)1 : (byte)0, spec, (byte**)paudioBuf, (uint*)paudioLen);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(ref SDLIOStream src, bool closeio, SDLAudioSpec* spec, ref byte* audioBuf, ref uint audioLen)
		{
			fixed (SDLIOStream* psrc = &src)
			{
				fixed (byte** paudioBuf = &audioBuf)
				{
					fixed (uint* paudioLen = &audioLen)
					{
						byte ret = LoadWAVIONative((SDLIOStream*)psrc, closeio ? (byte)1 : (byte)0, spec, (byte**)paudioBuf, (uint*)paudioLen);
						return ret != 0;
					}
				}
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(SDLIOStream* src, bool closeio, ref SDLAudioSpec spec, ref byte* audioBuf, ref uint audioLen)
		{
			fixed (SDLAudioSpec* pspec = &spec)
			{
				fixed (byte** paudioBuf = &audioBuf)
				{
					fixed (uint* paudioLen = &audioLen)
					{
						byte ret = LoadWAVIONative(src, closeio ? (byte)1 : (byte)0, (SDLAudioSpec*)pspec, (byte**)paudioBuf, (uint*)paudioLen);
						return ret != 0;
					}
				}
			}
		}

		/// <summary>
		/// Load the audio data of a WAVE file into memory.<br/>
		/// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to<br/>
		/// be valid pointers. The entire data portion of the file is then loaded into<br/>
		/// memory and decoded if necessary.<br/>
		/// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and<br/>
		/// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and<br/>
		/// A-law and mu-law (8 bits). Other formats are currently unsupported and<br/>
		/// cause an error.<br/>
		/// If this function succeeds, the return value is zero and the pointer to the<br/>
		/// audio data allocated by the function is written to `audio_buf` and its<br/>
		/// length in bytes to `audio_len`. The SDL_AudioSpec members `freq`,<br/>
		/// `channels`, and `format` are set to the values of the audio data in the<br/>
		/// buffer.<br/>
		/// It's necessary to use SDL_free() to free the audio data returned in<br/>
		/// `audio_buf` when it is no longer used.<br/>
		/// Because of the underspecification of the .WAV format, there are many<br/>
		/// problematic files in the wild that cause issues with strict decoders. To<br/>
		/// provide compatibility with these files, this decoder is lenient in regards<br/>
		/// to the truncation of the file, the fact chunk, and the size of the RIFF<br/>
		/// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,<br/>
		/// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to<br/>
		/// tune the behavior of the loading process.<br/>
		/// Any file that is invalid (due to truncation, corruption, or wrong values in<br/>
		/// the headers), too big, or unsupported causes an error. Additionally, any<br/>
		/// critical I/O error from the data source will terminate the loading process<br/>
		/// with an error. The function returns NULL on error and in all cases (with<br/>
		/// the exception of `src` being NULL), an appropriate error message will be<br/>
		/// set.<br/>
		/// It is required that the data source supports seeking.<br/>
		/// Example:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile("sample.wav", "rb"), true, <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// Note that the SDL_LoadWAV function does this same thing for you, but in a<br/>
		/// less messy way:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV("sample.wav", <br/>
		/// &spec<br/>
		/// , <br/>
		/// &buf<br/>
		/// , <br/>
		/// &len<br/>
		/// );<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAVIO(ref SDLIOStream src, bool closeio, ref SDLAudioSpec spec, ref byte* audioBuf, ref uint audioLen)
		{
			fixed (SDLIOStream* psrc = &src)
			{
				fixed (SDLAudioSpec* pspec = &spec)
				{
					fixed (byte** paudioBuf = &audioBuf)
					{
						fixed (uint* paudioLen = &audioLen)
						{
							byte ret = LoadWAVIONative((SDLIOStream*)psrc, closeio ? (byte)1 : (byte)0, (SDLAudioSpec*)pspec, (byte**)paudioBuf, (uint*)paudioLen);
							return ret != 0;
						}
					}
				}
			}
		}

		/// <summary>
		/// Loads a WAV from a file path.<br/>
		/// This is a convenience function that is effectively the same as:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile(path, "rb"), true, spec, audio_buf, audio_len);<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte LoadWAVNative(byte* path, SDLAudioSpec* spec, byte** audioBuf, uint* audioLen)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte*, SDLAudioSpec*, byte**, uint*, byte>)funcTable[361])(path, spec, audioBuf, audioLen);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, nint, nint, nint, byte>)funcTable[361])((nint)path, (nint)spec, (nint)audioBuf, (nint)audioLen);
			#endif
		}

		/// <summary>
		/// Loads a WAV from a file path.<br/>
		/// This is a convenience function that is effectively the same as:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile(path, "rb"), true, spec, audio_buf, audio_len);<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAV(byte* path, SDLAudioSpec* spec, byte** audioBuf, uint* audioLen)
		{
			byte ret = LoadWAVNative(path, spec, audioBuf, audioLen);
			return ret != 0;
		}

		/// <summary>
		/// Loads a WAV from a file path.<br/>
		/// This is a convenience function that is effectively the same as:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile(path, "rb"), true, spec, audio_buf, audio_len);<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAV(ref byte path, SDLAudioSpec* spec, byte** audioBuf, uint* audioLen)
		{
			fixed (byte* ppath = &path)
			{
				byte ret = LoadWAVNative((byte*)ppath, spec, audioBuf, audioLen);
				return ret != 0;
			}
		}

		/// <summary>
		/// Loads a WAV from a file path.<br/>
		/// This is a convenience function that is effectively the same as:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile(path, "rb"), true, spec, audio_buf, audio_len);<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAV(ReadOnlySpan<byte> path, SDLAudioSpec* spec, byte** audioBuf, uint* audioLen)
		{
			fixed (byte* ppath = path)
			{
				byte ret = LoadWAVNative((byte*)ppath, spec, audioBuf, audioLen);
				return ret != 0;
			}
		}

		/// <summary>
		/// Loads a WAV from a file path.<br/>
		/// This is a convenience function that is effectively the same as:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile(path, "rb"), true, spec, audio_buf, audio_len);<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAV(string path, SDLAudioSpec* spec, byte** audioBuf, uint* audioLen)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (path != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(path);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(path, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			byte ret = LoadWAVNative(pStr0, spec, audioBuf, audioLen);
			if (pStrSize0 >= Utils.MaxStackallocSize)
			{
				Utils.Free(pStr0);
			}
			return ret != 0;
		}

		/// <summary>
		/// Loads a WAV from a file path.<br/>
		/// This is a convenience function that is effectively the same as:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile(path, "rb"), true, spec, audio_buf, audio_len);<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAV(byte* path, ref SDLAudioSpec spec, byte** audioBuf, uint* audioLen)
		{
			fixed (SDLAudioSpec* pspec = &spec)
			{
				byte ret = LoadWAVNative(path, (SDLAudioSpec*)pspec, audioBuf, audioLen);
				return ret != 0;
			}
		}

		/// <summary>
		/// Loads a WAV from a file path.<br/>
		/// This is a convenience function that is effectively the same as:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile(path, "rb"), true, spec, audio_buf, audio_len);<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAV(ref byte path, ref SDLAudioSpec spec, byte** audioBuf, uint* audioLen)
		{
			fixed (byte* ppath = &path)
			{
				fixed (SDLAudioSpec* pspec = &spec)
				{
					byte ret = LoadWAVNative((byte*)ppath, (SDLAudioSpec*)pspec, audioBuf, audioLen);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Loads a WAV from a file path.<br/>
		/// This is a convenience function that is effectively the same as:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile(path, "rb"), true, spec, audio_buf, audio_len);<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAV(ReadOnlySpan<byte> path, ref SDLAudioSpec spec, byte** audioBuf, uint* audioLen)
		{
			fixed (byte* ppath = path)
			{
				fixed (SDLAudioSpec* pspec = &spec)
				{
					byte ret = LoadWAVNative((byte*)ppath, (SDLAudioSpec*)pspec, audioBuf, audioLen);
					return ret != 0;
				}
			}
		}

		/// <summary>
		/// Loads a WAV from a file path.<br/>
		/// This is a convenience function that is effectively the same as:<br/>
		/// ```c<br/>
		/// SDL_LoadWAV_IO(SDL_IOFromFile(path, "rb"), true, spec, audio_buf, audio_len);<br/>
		/// ```<br/>
		/// <br/>
		/// This function returns false if the .WAV file cannot be opened,<br/>
		/// uses an unknown data format, or is corrupt; call SDL_GetError()<br/>
		/// for more information.<br/>
		/// When the application is done with the data returned in<br/>
		/// `audio_buf`, it should call SDL_free() to dispose of it.<br/>
		/// <br/>
		/// It is safe to call this function from any thread.<br/>
		/// <br/>
		/// <br/>
		/// </summary>
		public static bool LoadWAV(string path, ref SDLAudioSpec spec, byte** audioBuf, uint* audioLen)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (path != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(path);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(path, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			fixed (SDLAudioSpec* pspec = &spec)
			{
				byte ret = LoadWAVNative(pStr0, (SDLAudioSpec*)pspec, audioBuf, audioLen);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
				return ret != 0;
			}
		}
	}
}
